{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "KNOWLEDGE GRAPH IMPORT & ENTITY RESOLUTION PIPELINE (FIXED)\n",
      "======================================================================\n",
      "\n",
      "[STEP 1/3] Importing JSONL data...\n",
      "[INFO] Processing line 50... (success=49, failed=0, skipped=0)\n",
      "\t took 2.4175379276275635 seconds\n",
      "[INFO] Processing line 100... (success=99, failed=0, skipped=0)\n",
      "\t took 5.129435777664185 seconds\n",
      "[INFO] Processing line 150... (success=149, failed=0, skipped=0)\n",
      "\t took 8.505815982818604 seconds\n",
      "[INFO] Processing line 200... (success=199, failed=0, skipped=0)\n",
      "\t took 14.655655860900879 seconds\n",
      "[INFO] Processing line 250... (success=249, failed=0, skipped=0)\n",
      "\t took 18.87693476676941 seconds\n",
      "[INFO] Processing line 300... (success=299, failed=0, skipped=0)\n",
      "\t took 24.275864839553833 seconds\n",
      "[INFO] Processing line 350... (success=349, failed=0, skipped=0)\n",
      "\t took 29.374151945114136 seconds\n",
      "[INFO] Processing line 400... (success=399, failed=0, skipped=0)\n",
      "\t took 35.32025980949402 seconds\n",
      "[INFO] Processing line 450... (success=449, failed=0, skipped=0)\n",
      "\t took 42.1365327835083 seconds\n",
      "[INFO] Processing line 500... (success=499, failed=0, skipped=0)\n",
      "\t took 48.198460817337036 seconds\n",
      "[INFO] Processing line 550... (success=549, failed=0, skipped=0)\n",
      "\t took 56.18822979927063 seconds\n",
      "[INFO] Processing line 600... (success=599, failed=0, skipped=0)\n",
      "\t took 64.13902878761292 seconds\n",
      "[INFO] Processing line 650... (success=649, failed=0, skipped=0)\n",
      "\t took 71.9008367061615 seconds\n",
      "\n",
      "=== Import summary ===\n",
      "Total lines read:     652\n",
      "Successful cases:     652\n",
      "Failed cases:         0\n",
      "Skipped lines:        0\n",
      "Runtime (s):           72.4458680152893\n",
      "\n",
      "[STEP 2/3] Previewing potential duplicates...\n",
      "\n",
      "======================================================================\n",
      "                    DUPLICATE PREVIEW (No Merging)                    \n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "                         CURRENT GRAPH STATE                          \n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š OVERALL:\n",
      "  Total Nodes:         17,614\n",
      "  Total Relationships: 31,898\n",
      "\n",
      "ðŸ“¦ NODES BY TYPE:\n",
      "  Person               4,651\n",
      "  TopicEntity          2,659\n",
      "  Email                2,217\n",
      "  Event                1,924\n",
      "  Concern              1,802\n",
      "  Decision             1,245\n",
      "  Location             818\n",
      "  Financial            612\n",
      "  Case                 605\n",
      "  Document             493\n",
      "  Organization         289\n",
      "  Place                224\n",
      "  RxNormDrug           75\n",
      "\n",
      "ðŸ”— RELATIONSHIPS BY TYPE:\n",
      "  SENT_TO                   6,104\n",
      "  EMAIL_MENTIONS_TOPIC      5,219\n",
      "  MENTIONS_PERSON_ENRICHED  4,072\n",
      "  HAS_EMAIL                 1,988\n",
      "  SENT                      1,972\n",
      "  HAS_EVENT                 1,924\n",
      "  HAS_CONCERN               1,802\n",
      "  EMAIL_MENTIONS_LOCATION   1,569\n",
      "  HAS_DECISION              1,245\n",
      "  REFERS_TO_EMAIL           1,243\n",
      "  AFFILIATED_WITH           1,107\n",
      "  HAS_ATTACHMENT            786\n",
      "  CASE_HAS_DOCUMENT         727\n",
      "  HAS_FINANCIAL             612\n",
      "  CASE_MENTIONS             475\n",
      "  EMAIL_MENTIONS_PLACE      473\n",
      "  FORWARDED_MESSAGE         325\n",
      "  EMAIL_MENTIONS_DRUG       229\n",
      "  SUBSIDIARY_OF             26\n",
      "\n",
      "ðŸ‘¥ PERSON DETAILS:\n",
      "  Total Persons:       4,651\n",
      "  With Email:          1,021\n",
      "  Without Email:       3,630\n",
      "\n",
      "ðŸ“§ OTHER:\n",
      "  Organizations:       289\n",
      "  Emails:              2,217\n",
      "======================================================================\n",
      "\n",
      "ðŸ‘¥ POTENTIAL PERSON DUPLICATES (threshold=0.95):\n",
      "  Found 808 potential duplicate pair(s):\n",
      "\n",
      "  [1] Similarity: 1.000\n",
      "      Person A: Deborah Y. Butcher (Deborah.Y.Butcher@usdOJ.gov)\n",
      "      Person B: Deborah Y. Butcher (Deborah.Y.Butcher@usdoj.gov)\n",
      "\n",
      "  [2] Similarity: 1.000\n",
      "      Person A: Paul D. Kleissle (Paui.D.Kleiss!e@usdoj.gov)\n",
      "      Person B: Paul D. Kleissle (Paul.D.Kleissle@usdoj.gov)\n",
      "\n",
      "  [3] Similarity: 1.000\n",
      "      Person A: Donald Walker (Donald.Walker@McKesson.com)\n",
      "      Person B: Donald Walker (donald.walker@mckesson.com)\n",
      "\n",
      "  [4] Similarity: 1.000\n",
      "      Person A: Bruce (Bruce.Russell@McKesson.com)\n",
      "      Person B: Bruce Russell (bruce.russell@mckesson.com)\n",
      "\n",
      "  [5] Similarity: 1.000\n",
      "      Person A: Andrew Moore (andrew.moors@mckesson.com)\n",
      "      Person B: Andrew Moore (amoore@mckesson.com)\n",
      "\n",
      "  [6] Similarity: 1.000\n",
      "      Person A: Joe Lumpkin (jae.lumpkin@mckesson.com)\n",
      "      Person B: Joe Lumpkin (joe.iumpkin@mckesson.com)\n",
      "\n",
      "  [7] Similarity: 1.000\n",
      "      Person A: Dave Gustin (dave.gustin@mckesson.com)\n",
      "      Person B: Dave Gustin (Dave.Gustin@McKesson.com)\n",
      "\n",
      "  [8] Similarity: 1.000\n",
      "      Person A: Michael Oriente (michael.oriente@mckesson.com)\n",
      "      Person B: Michael Oriente (Michael.Oriente@McKesson.com)\n",
      "\n",
      "  [9] Similarity: 1.000\n",
      "      Person A: Michael Oriente (michael.oriente@mckesson.com)\n",
      "      Person B: Michael Oriente (Michael.Orierte@McKesson.com)\n",
      "\n",
      "  [10] Similarity: 1.000\n",
      "      Person A: Joseph Ganley (Joe.Ganley@McKesson.com)\n",
      "      Person B: Joe Ganley (joe.ganley@mckesson.com)\n",
      "\n",
      "  ... and 798 more duplicate pair(s)\n",
      "\n",
      "ðŸ¢ POTENTIAL ORGANIZATION DUPLICATES (threshold=0.9):\n",
      "  Found 50 potential duplicate pair(s):\n",
      "\n",
      "  [1] Similarity: 1.000\n",
      "      Org A: unknown\n",
      "      Org B: unknown\n",
      "\n",
      "  ... and 40 more duplicate pair(s)\n",
      "\n",
      "======================================================================\n",
      "SUMMARY: 858 potential merge(s) identified\n",
      "  â€¢ 808 person merge(s)\n",
      "  â€¢ 50 organization merge(s)\n",
      "\n",
      "Estimated node reduction: 858 nodes\n",
      "======================================================================\n",
      "\n",
      "[STEP 3/3] Running entity resolution...\n",
      "\n",
      "======================================================================\n",
      "                      ENTITY RESOLUTION STARTING                      \n",
      "======================================================================\n",
      "\n",
      "[1/4] Capturing BEFORE statistics...\n",
      "\n",
      "======================================================================\n",
      "                       BEFORE ENTITY RESOLUTION                       \n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š OVERALL:\n",
      "  Total Nodes:         17,614\n",
      "  Total Relationships: 31,898\n",
      "\n",
      "ðŸ“¦ NODES BY TYPE:\n",
      "  Person               4,651\n",
      "  TopicEntity          2,659\n",
      "  Email                2,217\n",
      "  Event                1,924\n",
      "  Concern              1,802\n",
      "  Decision             1,245\n",
      "  Location             818\n",
      "  Financial            612\n",
      "  Case                 605\n",
      "  Document             493\n",
      "  Organization         289\n",
      "  Place                224\n",
      "  RxNormDrug           75\n",
      "\n",
      "ðŸ”— RELATIONSHIPS BY TYPE:\n",
      "  SENT_TO                   6,104\n",
      "  EMAIL_MENTIONS_TOPIC      5,219\n",
      "  MENTIONS_PERSON_ENRICHED  4,072\n",
      "  HAS_EMAIL                 1,988\n",
      "  SENT                      1,972\n",
      "  HAS_EVENT                 1,924\n",
      "  HAS_CONCERN               1,802\n",
      "  EMAIL_MENTIONS_LOCATION   1,569\n",
      "  HAS_DECISION              1,245\n",
      "  REFERS_TO_EMAIL           1,243\n",
      "  AFFILIATED_WITH           1,107\n",
      "  HAS_ATTACHMENT            786\n",
      "  CASE_HAS_DOCUMENT         727\n",
      "  HAS_FINANCIAL             612\n",
      "  CASE_MENTIONS             475\n",
      "  EMAIL_MENTIONS_PLACE      473\n",
      "  FORWARDED_MESSAGE         325\n",
      "  EMAIL_MENTIONS_DRUG       229\n",
      "  SUBSIDIARY_OF             26\n",
      "\n",
      "ðŸ‘¥ PERSON DETAILS:\n",
      "  Total Persons:       4,651\n",
      "  With Email:          1,021\n",
      "  Without Email:       3,630\n",
      "\n",
      "ðŸ“§ OTHER:\n",
      "  Organizations:       289\n",
      "  Emails:              2,217\n",
      "======================================================================\n",
      "\n",
      "[2/4] Resolving Persons (threshold=0.95)...\n",
      "  Found 808 potential person duplicates\n",
      "    Merging Deborah.Y.Butcher@usdoj.gov -> Deborah.Y.Butcher@usdOJ.gov (similarity: 1.000)\n",
      "    Merging Paul.D.Kleissle@usdoj.gov -> Paui.D.Kleiss!e@usdoj.gov (similarity: 1.000)\n",
      "    Merging donald.walker@mckesson.com -> Donald.Walker@McKesson.com (similarity: 1.000)\n",
      "    Merging bruce.russell@mckesson.com -> Bruce.Russell@McKesson.com (similarity: 1.000)\n",
      "    Merging amoore@mckesson.com -> andrew.moors@mckesson.com (similarity: 1.000)\n",
      "    Merging joe.iumpkin@mckesson.com -> jae.lumpkin@mckesson.com (similarity: 1.000)\n",
      "    Merging Dave.Gustin@McKesson.com -> dave.gustin@mckesson.com (similarity: 1.000)\n",
      "    Merging Michael.Oriente@McKesson.com -> michael.oriente@mckesson.com (similarity: 1.000)\n",
      "    Merging Michael.Orierte@McKesson.com -> michael.oriente@mckesson.com (similarity: 1.000)\n",
      "    Merging joe.ganley@mckesson.com -> Joe.Ganley@McKesson.com (similarity: 1.000)\n",
      "    Merging nate.hartle@mckesson.com -> nhartle@mckesson.com (similarity: 1.000)\n",
      "    Merging bill.mahoney@mckesson.com -> Bill.Mahoney@McKesson.com (similarity: 1.000)\n",
      "    Merging Gary.Hilliard@McKesson.com -> gary.hilliard@mckesson.com (similarity: 1.000)\n",
      "    Merging Michael.Orierte@McKesson.com -> Michael.Oriente@McKesson.com (similarity: 1.000)\n",
      "    Merging paul.julian@mckesson.com -> Paul.Julian@McKesson.com (similarity: 1.000)\n",
      "    Merging joe.ganley@mckesson.com -> joe.qanley@mckesson.com (similarity: 1.000)\n",
      "    Merging smelville@cephalon.com -> smelvill@cephalon.com (similarity: 1.000)\n",
      "    Merging dwayne.pinon@walgreens.com -> Dwayne.Pinon@walgreens.com (similarity: 1.000)\n",
      "    Merging tasha.polster@walgreens.com -> Tasha.Polster@walgreens.com (similarity: 1.000)\n",
      "    Merging jdiebert@walgreens.com -> jennifer.diebert@walgreens.com (similarity: 1.000)\n",
      "    Merging sday@walgreens.com -> susanday@walgreens.com (similarity: 1.000)\n",
      "    Merging jferry@walgreens.com -> joeferry@walgreens.com (similarity: 1.000)\n",
      "    Merging ahiney@walgreens.com -> anne.hiney@walgreens.com (similarity: 1.000)\n",
      "    Merging katwell@walgreens.com -> kristine.atwell@walgreens.com (similarity: 1.000)\n",
      "    Merging steve.kneller@walgreens.com -> skneller@walgreens.com (similarity: 1.000)\n",
      "    Merging john.coman@walgreens.com -> jcoman@walgreens.com (similarity: 1.000)\n",
      "    Merging Karen.Harper@covidien.com -> karen.harper@covidien.com (similarity: 1.000)\n",
      "    Merging Karen.Harper@Covidien.com -> karen.harper@covidien.com (similarity: 1.000)\n",
      "    Merging victor.borelli@covidien.com -> Vlctor.borelli@covidien.com (similarity: 1.000)\n",
      "    Merging Victor.Borelli@covidien.com -> Vlctor.borelli@covidien.com (similarity: 1.000)\n",
      "    Merging Karen.Harper@Covidien.com -> Karen.Harper@covidien.com (similarity: 1.000)\n",
      "    Merging Cathy.Stewart@covidien.com -> Cathy.Stewart@Covidien.com (similarity: 1.000)\n",
      "    Merging Eileen.Spaulding@covidien.com -> eileen.spaulding@covidien.com (similarity: 1.000)\n",
      "    Merging bill.ratiiff@covidien.com -> bill.ratliff@covidien.com (similarity: 1.000)\n",
      "    Merging Bill.Ratliff@Covidien.com -> bill.ratliff@covidien.com (similarity: 1.000)\n",
      "    Merging Bill.Ratliff@Covidien.com -> bill.ratiiff@covidien.com (similarity: 1.000)\n",
      "    Merging victor.borelli@covidien.com -> Victor.Borelli@Covidien.com (similarity: 1.000)\n",
      "    Merging Victor.Borelli@covidien.com -> Victor.Borelli@Covidien.com (similarity: 1.000)\n",
      "    Merging Victor.Borelli@covidien.com -> victor.borelli@covidien.com (similarity: 1.000)\n",
      "    Merging larry.shaffer@watson.com -> Larry.Shaffer@watson.com (similarity: 1.000)\n",
      "    Merging JMCCORMICK@actavis.com -> jmccormick@actavis.com (similarity: 1.000)\n",
      "    Merging JMCCORMICK@Actavis.com -> jmccormick@actavis.com (similarity: 1.000)\n",
      "    Merging nbaran@actavis.com -> NBARAN@actavis.com (similarity: 1.000)\n",
      "    Merging JMCCORMICK@Actavis.com -> JMCCORMICK@actavis.com (similarity: 1.000)\n",
      "    Merging JackOack.crowley@pharma.com -> jack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging Jack.Crowley@pharma.com -> jack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging burt.rosen@pharma.com -> Burt.Rosen@pharma.com (similarity: 1.000)\n",
      "    Merging Jack.Crowley@pharma.com -> JackOack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging Stephen.Seid@pharma.com -> Stephenfsteve.seid@pharma.com (similarity: 1.000)\n",
      "    Merging Charles.Forsaith@pharma.com -> charles.forsaith@pharma.com (similarity: 1.000)\n",
      "    Merging Gina.Limer@pharma.com -> gina.limer@pharma.com (similarity: 1.000)\n",
      "    Merging Elizabeth.Adams@pharma.com -> elizabeth.adams@pharma.com (similarity: 1.000)\n",
      "    Merging gaiLtetzlaff@mallinckrodt.com -> Gail.Tetzlaff@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Matthew.Day@tevapharm.com -> matthew.day@tevapharm.com (similarity: 1.000)\n",
      "    Merging Kevin.lneutzer@tevapharm.com -> Kevin.Kreutzer@tevapharm.com (similarity: 1.000)\n",
      "    Merging cchikwendu@ITS.JNJ.COM -> CCHIKWEN@ITS.JNJ.COM (similarity: 1.000)\n",
      "    Merging pkatrina@ITS.JNJ.COM -> pkatrina@ITS.JNJ.com (similarity: 1.000)\n",
      "    Merging kpurifoy@ITS.JNJ.COM -> pkatrina@ITS.JNJ.com (similarity: 1.000)\n",
      "    Merging mdempsey@ITS.JNJ.COM -> MDempse3@its.jnj.com (similarity: 1.000)\n",
      "    Merging kpurifoy@ITS.JNJ.COM -> pkatrina@ITS.JNJ.COM (similarity: 1.000)\n",
      "    Merging czimmerman@amerisourcebergen.com -> CZimmerman@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging pross@amerisourcebergen.com -> PRoss@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging DMay@amerisourcebergen.com -> dmay@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging dmay@AmerisourceBergen.com -> dmay@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging SMays@amerisourcebergen.com -> smays@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging smavs@amerisourcebergen.com -> smays@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging rv1Guerreiro@amerisourcebergen.com -> MGuerreiro@amerisourcebergen.com (similarity: 0.950)\n",
      "    Merging rnorton@amerisourcebergen.com -> RNorton@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging smavs@amerisourcebergen.com -> SMays@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging hzenk@amerisourcebergen.com -> FLZenk@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging ehazewski@amerisourcebergen.com -> EHazewski@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging dmay@AmerisourceBergen.com -> DMay@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging tamara.chapman-wagner@jfs.ohio.gov -> Tamara.Chapman-Wagner@jfs.ohio.gov (similarity: 1.000)\n",
      "    Merging RHelfric@ITSJNJ.com -> RHelfnc@ITSJNJ.com (similarity: 1.000)\n",
      "    Merging Walker.Lisa@Endo.com -> Walker.lisa@endo.com (similarity: 1.000)\n",
      "    Merging Munroe.Brian@Endo.com -> munroe.brian@endo.com (similarity: 1.000)\n",
      "    Merging munroe.bhan@endo.com -> munroe.brian@endo.com (similarity: 1.000)\n",
      "    Merging munroe.bhan@endo.com -> Munroe.Brian@Endo.com (similarity: 1.000)\n",
      "    Merging JMcCormack@nacds.org -> JMcCormack@NACDS.org (similarity: 1.000)\n",
      "    Merging JMeCormack@NACDS.org -> JMcCormack@NACDS.org (similarity: 1.000)\n",
      "    Merging JMeCormack@NACDS.org -> JMcCormack@nacds.org (similarity: 1.000)\n",
      "    Merging NACDSMedia@nacds.org -> nacdsmedia@nacds.org (similarity: 1.000)\n",
      "    Merging pkelly@hdmanet.org -> pkellv@hdmanet.org (similarity: 1.000)\n",
      "    Merging icosgrove@hdmanet.org -> jcosgrove@hdmanet.org (similarity: 1.000)\n",
      "    Merging icosqrove@hdmanet.org -> jcosgrove@hdmanet.org (similarity: 1.000)\n",
      "    Merging icosqrove@hdmanet.org -> icosgrove@hdmanet.org (similarity: 1.000)\n",
      "    Merging Robert.Giacalone@cardinalhealth.com -> robert.giacalone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging robert.giacalone@Cardinalhealth.com -> robert.giacalone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Alvey.Squires@cardinalhealth.com -> asquires@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Erik.Lilje@cardinalhealth.com -> erik.lilje@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging connie.woodburn@cardinalhealth.com -> Connie.Woodburn@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging steve.reardon@cardinalhealth.com -> Steve.Reardon@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging robert.giacalone@Cardinalhealth.com -> Robert.Giacalone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Michael.Mone@cardinalhealth.com -> michael.mone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging ullrich.mayeski@cardinalhealth.com -> fullrich.mayeski@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging pwilkinson@example.com ->  pwilkinson@example.com (similarity: 1.000)\n",
      "    Merging GEuson@hdsmith.com -> geuson@hdsmith.com (similarity: 1.000)\n",
      "    Merging jgiglio@painfoundation.org -> JGiglio@painfoundation.org (similarity: 1.000)\n",
      "    Merging pkelly@hda.org -> pkeJly@hda.org (similarity: 1.000)\n",
      "    Merging ebrantlev@qualitestrx.com -> EBrantley@QualiTestRx.com (similarity: 1.000)\n",
      "    Merging ebrantley@qualitestrx.com -> EBrantley@QualiTestRx.com (similarity: 1.000)\n",
      "    Merging ebrantley@qualitestrx.com -> ebrantlev@qualitestrx.com (similarity: 1.000)\n",
      "    Merging valuetrak@valuecentric.com -> valuetrack@valuecentric.com (similarity: 1.000)\n",
      "    Merging valueTrak@valuecentric.com -> valuetrack@valuecentric.com (similarity: 1.000)\n",
      "    Merging valueTrak@valuecentric.com -> valuetrak@valuecentric.com (similarity: 1.000)\n",
      "    Merging BILLNOPAIN@aol.com -> billnopain@aol.com (similarity: 1.000)\n",
      "    Merging cdnelson@ups.com -> CDNelson@ups.com (similarity: 1.000)\n",
      "    Merging biohnston@ups.com -> BJohnston@ups.com (similarity: 1.000)\n",
      "    Merging kk@rubicondc.com -> KK@rubicondc.com (similarity: 1.000)\n",
      "    Merging PRATYCZ@discount-drugmart.com -> pratvcz@discount-drugmart.com (similarity: 0.957)\n",
      "    Merging ipollard@schd.org -> jpollard@schd.org (similarity: 1.000)\n",
      "    Merging steve.reardon@cardinai.com -> steve.reardon@cardinal.com (similarity: 1.000)\n",
      "    Merging Steve Reardon -> steve.reardon@cardinal.com (similarity: 1.000)\n",
      "    Merging steve.reardon@cardinalhealth.com -> steve.reardon@cardinal.com (similarity: 1.000)\n",
      "    Merging Steve Reardon -> steve.reardon@cardinai.com (similarity: 1.000)\n",
      "    Merging steve.reardon@cardinalhealth.com -> steve.reardon@cardinai.com (similarity: 1.000)\n",
      "    Merging Steve Mays -> smays@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging SMays@amerisourcebergen.com -> Steve Mays (similarity: 1.000)\n",
      "    Merging smavs@amerisourcebergen.com -> Steve Mays (similarity: 1.000)\n",
      "    Merging Steve.Lawrence@cardinalhealth.com -> Steve Lawrence (similarity: 1.000)\n",
      "    Merging Steve.Falk@cardinalhealth.com -> Steve Falk (similarity: 1.000)\n",
      "    Merging SAnderson@NACDS.org -> Steve Anderson (similarity: 1.000)\n",
      "    Merging steve.reardon@cardinalhealth.com -> Steve Reardon (similarity: 1.000)\n",
      "    Merging Steve Zollo -> szollo@example.com (similarity: 1.000)\n",
      "    Merging Steve Bishop -> Steve.Bishop@pharma.com (similarity: 1.000)\n",
      "    Merging Heather.Jones@parpharm.com -> Heather Jones (similarity: 1.000)\n",
      "    Merging dmyers@actavis.com -> David Myers (similarity: 1.000)\n",
      "    Merging David May -> dmay@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging david.reiter@walgreens.com -> David Reiter (similarity: 1.000)\n",
      "    Merging David Domann -> ddomann@example.com (similarity: 1.000)\n",
      "    Merging David May -> DMay@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging David Graziano -> david.graziano@mckesson.com (similarity: 1.000)\n",
      "    Merging joranson@wisc.edu -> joranson@facstaff.wisc.edu (similarity: 1.000)\n",
      "    Merging David Joranson -> joranson@facstaff.wisc.edu (similarity: 1.000)\n",
      "    Merging David Joranson -> joranson@wisc.edu (similarity: 1.000)\n",
      "    Merging David Rosen -> David.Rosen@pharma.com (similarity: 1.000)\n",
      "    Merging David May -> dmay@AmerisourceBergen.com (similarity: 1.000)\n",
      "    Merging Donald.Walker@McKesson.com -> Donald Walker (similarity: 1.000)\n",
      "    Merging donald.walker@mckesson.com -> Donald Walker (similarity: 1.000)\n",
      "    Merging Donald.Walker@MeKesson.com -> Donald Walker (similarity: 1.000)\n",
      "    Merging Donald.Walker@MeKesson.com -> Donald.Walker@McKesson.com (similarity: 1.000)\n",
      "    Merging Donald.Lohman@Covidien.com -> Donald A. Lohman (similarity: 1.000)\n",
      "    Merging Donald.Lohman@mallinckrodt.com -> Donald A. Lohman (similarity: 1.000)\n",
      "    Merging Donald.Walker@MeKesson.com -> donald.walker@mckesson.com (similarity: 1.000)\n",
      "    Merging Donald.Lohman@mallinckrodt.com -> Donald.Lohman@Covidien.com (similarity: 1.000)\n",
      "    Merging Jack.CrowIey@pharma.cam -> jack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging jack.crowleyPpharma.com -> jack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging Jack Crowley -> jack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging crowleyassoc@att.net -> jack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging Jack.CrowIey@pharma.cam -> JackOack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging jack.crowleyPpharma.com -> JackOack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging Jack Crowley -> JackOack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging crowleyassoc@att.net -> JackOack.crowley@pharma.com (similarity: 1.000)\n",
      "    Merging jack.crowleyPpharma.com -> Jack.CrowIey@pharma.cam (similarity: 1.000)\n",
      "    Merging Jack Crowley -> Jack.CrowIey@pharma.cam (similarity: 1.000)\n",
      "    Merging Jack.Crowley@pharma.com -> Jack.CrowIey@pharma.cam (similarity: 1.000)\n",
      "    Merging crowleyassoc@att.net -> Jack.CrowIey@pharma.cam (similarity: 1.000)\n",
      "    Merging Jack Crowley -> jack.crowleyPpharma.com (similarity: 1.000)\n",
      "    Merging Jack.Crowley@pharma.com -> jack.crowleyPpharma.com (similarity: 1.000)\n",
      "    Merging crowleyassoc@att.net -> jack.crowleyPpharma.com (similarity: 1.000)\n",
      "    Merging Jack.Crowley@pharma.com -> Jack Crowley (similarity: 1.000)\n",
      "    Merging crowleyassoc@att.net -> Jack Crowley (similarity: 1.000)\n",
      "    Merging crowleyassoc@att.net -> Jack.Crowley@pharma.com (similarity: 1.000)\n",
      "    Merging rex.swords@walgreens.com -> Rex Swords (similarity: 1.000)\n",
      "    Merging Customers -> customers (similarity: 1.000)\n",
      "    Merging Philip Strassburger -> Philip.Strassburger@pharma.com (similarity: 1.000)\n",
      "    Merging Laura.Watson@pharma.com -> Laura Watson (similarity: 1.000)\n",
      "    Merging Valerie Chikwendu -> CCHIKWEN@ITS.JNJ.COM (similarity: 1.000)\n",
      "    Merging cchikwendu@ITS.JNJ.COM -> Valerie Chikwendu (similarity: 1.000)\n",
      "    Merging James.Heins@pharma.com -> James Heins (similarity: 1.000)\n",
      "    Merging Kevin.Webb@mallinckrodt.com -> Kevin J Webb (similarity: 1.000)\n",
      "    Merging KNicholson@NACDS.org -> Kevin Nicholson (similarity: 1.000)\n",
      "    Merging Kevin.Kreutzer@tevapharm.com -> KKreutzer@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Kevin.lneutzer@tevapharm.com -> KKreutzer@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Kevin Kreutzer -> KKreutzer@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Kevin Kreutzer -> Kevin.Kreutzer@tevapharm.com (similarity: 1.000)\n",
      "    Merging Kevin Kreutzer -> Kevin.lneutzer@tevapharm.com (similarity: 1.000)\n",
      "    Merging Stacey Beckhardt -> sbeckhar@cephalon.com (similarity: 1.000)\n",
      "    Merging Stacey Cirillo -> Stacey.Cirillo@watson.com (similarity: 1.000)\n",
      "    Merging Stacey Fahrner -> sfahrner@primetherapeutics.com (similarity: 1.000)\n",
      "    Merging SHandza@cooneywaters.com -> Sarah Handza (similarity: 1.000)\n",
      "    Merging sarah.medina@mckesson.com -> Sarah.Medina@mckessori.com (similarity: 1.000)\n",
      "    Merging Lisa D. Sullivan -> lisa.d.sullivan@usdoj.gov (similarity: 1.000)\n",
      "    Merging Dr.Lisa.Miller@pharma.com -> Lisa Miller (similarity: 1.000)\n",
      "    Merging Lisa Penn -> Lisa.Penn@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Lisa Walker -> Walker.lisa@endo.com (similarity: 1.000)\n",
      "    Merging Lisa.Cardetti@mallinckrodt.com -> Lisa.Cardetti@Covidien.com (similarity: 1.000)\n",
      "    Merging Lisa M Cardetti -> Lisa.Cardetti@Covidien.com (similarity: 1.000)\n",
      "    Merging Lisa M Cardetti -> Lisa.Cardetti@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Lisa Walker -> Walker.Lisa@Endo.com (similarity: 1.000)\n",
      "    Merging Lisa Kreiner -> LKreiner@discount-drugmart.com (similarity: 1.000)\n",
      "    Merging Lisa Clagg -> lisa.clagg@walgreens.com (similarity: 1.000)\n",
      "    Merging Michael R. Mapes -> mapes@usdoj.gov (similarity: 1.000)\n",
      "    Merging Michael Dorsey -> mdorsey@actavis.com (similarity: 1.000)\n",
      "    Merging Michael Oriente -> michael.oriente@mckesson.com (similarity: 1.000)\n",
      "    Merging michael.mone@cardinalhealth.com -> Michael Mone (similarity: 1.000)\n",
      "    Merging Michael Cochrane -> Michael.Cochrane@Andanet.com (similarity: 1.000)\n",
      "    Merging Michael.Oriente@McKesson.com -> Michael Oriente (similarity: 1.000)\n",
      "    Merging Michael.Orierte@McKesson.com -> Michael Oriente (similarity: 1.000)\n",
      "    Merging Michael Friedman -> friedman(a)pharma.com (similarity: 1.000)\n",
      "    Merging Michael Grissinger -> mgrissi@corus.jnj.com (similarity: 1.000)\n",
      "    Merging Michael Brzica -> mbrzica@primetherapeutics.com (similarity: 1.000)\n",
      "    Merging mperfetto@actavis.com -> Michael Perfetto (similarity: 1.000)\n",
      "    Merging Dwayne Pinon -> Dwayne.Pinon@walgreens.com (similarity: 1.000)\n",
      "    Merging Dwayne A. Pinon -> dwayne.pinon@walgreens.com (similarity: 1.000)\n",
      "    Merging Dwayne.Pinorr@wa!greens.com -> dwayne.pinon@walgreens.com (similarity: 1.000)\n",
      "    Merging Dwayne.Pinon@waigreens.com -> dwayne.pinon@walgreens.com (similarity: 1.000)\n",
      "    Merging Dwayne.Pinorr@wa!greens.com -> Dwayne A. Pinon (similarity: 1.000)\n",
      "    Merging Dwayne.Pinon@waigreens.com -> Dwayne A. Pinon (similarity: 1.000)\n",
      "    Merging Dwayne.Pinon@waigreens.com -> Dwayne.Pinorr@wa!greens.com (similarity: 1.000)\n",
      "    Merging mrmapes@gmail.com -> Mike Mapes (similarity: 1.000)\n",
      "    Merging Mike Post -> mike.post@mckesson.com (similarity: 1.000)\n",
      "    Merging Mike Kaufmann -> Mike.Kaufmann@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Mike Mone -> mike.mone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Mike Podgurski -> mpodgurski@riteaid.com (similarity: 1.000)\n",
      "    Merging dlobbi@example.com -> Danielle Lobbi (similarity: 1.000)\n",
      "    Merging Danielle Hagan -> danielle@nahigianstrategies.com (similarity: 1.000)\n",
      "    Merging Danielle Veira -> dveira@nahigianstrategies.com (similarity: 1.000)\n",
      "    Merging Donna Reid -> doreid@chpnet.org (similarity: 1.000)\n",
      "    Merging Terrence Terifay -> tterifay@cephalon.com (similarity: 1.000)\n",
      "    Merging matthew.day@tevapharm.com -> Matthew Day (similarity: 1.000)\n",
      "    Merging Matthew.Day@tevapharm.com -> Matthew Day (similarity: 1.000)\n",
      "    Merging Matthew Niskach -> matthew.niskach@gianteagle.com (similarity: 1.000)\n",
      "    Merging Matthew.Benkert@tevapharm.com -> Matthew Benkert (similarity: 1.000)\n",
      "    Merging Matthew.O'Donnell@pharma.com -> Matthew O'Donnell (similarity: 1.000)\n",
      "    Merging Matthew DiLoreto -> mdiloreto@hda.org (similarity: 1.000)\n",
      "    Merging Jeffrey Glover -> jeffrey.glover@mckesson.com (similarity: 1.000)\n",
      "    Merging Karen Harper -> karen.harper@covidien.com (similarity: 1.000)\n",
      "    Merging Karen Harper -> Karen.Harper@covidien.com (similarity: 1.000)\n",
      "    Merging Karen Stoedter -> KStoedter@actavis.com (similarity: 1.000)\n",
      "    Merging Karen Mankowski -> karen.mankowski@meijer.com (similarity: 1.000)\n",
      "    Merging Karen Lyons -> klyons@primetherapeutics.com (similarity: 1.000)\n",
      "    Merging Karen A. Sisson -> karen.sisson@walgreens.com (similarity: 1.000)\n",
      "    Merging Karen Harper -> Karen.Harper@Covidien.com (similarity: 1.000)\n",
      "    Merging Robert Helfrick -> RHelfnc@ITSJNJ.com (similarity: 1.000)\n",
      "    Merging RHelfric@ITSJNJ.com -> Robert Helfrick (similarity: 1.000)\n",
      "    Merging Robert Giacalone -> robert.giacalone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Robert.Giacalone@pharma.com -> robert.giacalone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging robert.brown@andanet.com -> Robert Brown (similarity: 1.000)\n",
      "    Merging Robert Kent -> rkentppi@att.net (similarity: 1.000)\n",
      "    Merging Robert.Giacalone@cardinalhealth.com -> Robert Giacalone (similarity: 1.000)\n",
      "    Merging robert.giacalone@Cardinalhealth.com -> Robert Giacalone (similarity: 1.000)\n",
      "    Merging Robert.Giacalone@pharma.com -> Robert Giacalone (similarity: 1.000)\n",
      "    Merging Robert.Giacalone@pharma.com -> Robert.Giacalone@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging dr.robert.reder@pharma.com -> reder.robert@endo.com (similarity: 1.000)\n",
      "    Merging robert.saner@ppsv.com -> Robert Saner (similarity: 1.000)\n",
      "    Merging Robert I. Brown -> Robert.I.Brown@example.invalid (similarity: 1.000)\n",
      "    Merging Robert.Giacalone@pharma.com -> robert.giacalone@Cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Robert.Josephson@pharma.com -> Robert Josephson (similarity: 1.000)\n",
      "    Merging Pete Slone -> Pete.Slone@McKesson.com (similarity: 1.000)\n",
      "    Merging peterslone1@gmail.com -> Pete.Slone@McKesson.com (similarity: 1.000)\n",
      "    Merging peterslone1@gmail.com -> Pete Slone (similarity: 1.000)\n",
      "    Merging PRATYCZ@discount-drugmart.com -> Pete Ratycz (similarity: 1.000)\n",
      "    Merging JoAnne.Levy@Covidien.com -> JoAnne Levy (similarity: 1.000)\n",
      "    Merging Joanne -> JoAnne (similarity: 1.000)\n",
      "    Merging Cathy.Stewart@Covidien.com -> Cathy Stewart (similarity: 1.000)\n",
      "    Merging Cathy.Stewart@covidien.com -> Cathy Stewart (similarity: 1.000)\n",
      "    Merging Paul D. Kleissle -> Paui.D.Kleiss!e@usdoj.gov (similarity: 1.000)\n",
      "    Merging Paul D. Kleissle -> Paul.D.Kleissle@usdoj.gov (similarity: 1.000)\n",
      "    Merging Paul Ross -> PRoss@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Paul.Plourd@cardinalhealth.com -> Paul Plourd (similarity: 1.000)\n",
      "    Merging Paul.Julian@McKesson.com -> Paul Julian (similarity: 1.000)\n",
      "    Merging paul.julian@mckesson.com -> Paul Julian (similarity: 1.000)\n",
      "    Merging Paul Goldenheim -> paul.goldenheim@pharma.com (similarity: 1.000)\n",
      "    Merging Paul Murden -> pmurden@gallaherswitzerland.ch (similarity: 1.000)\n",
      "    Merging pross@amerisourcebergen.com -> Paul Ross (similarity: 1.000)\n",
      "    Merging PAUL EVANS -> pevans@qualitestrx.com (similarity: 1.000)\n",
      "    Merging Elaine Thomet -> elaine.thomet@mckesson.com (similarity: 1.000)\n",
      "    Merging micheal.bishop@mckesson.com -> Micheal Bishop (similarity: 1.000)\n",
      "    Merging Customer Service -> customer service (similarity: 1.000)\n",
      "    Merging Jackie Pollard -> jpollard@schd.org (similarity: 1.000)\n",
      "    Merging ipollard@schd.org -> Jackie Pollard (similarity: 1.000)\n",
      "    Merging Jill McCormack -> JMcCormack@NACDS.org (similarity: 1.000)\n",
      "    Merging JMcCormack@nacds.org -> Jill McCormack (similarity: 1.000)\n",
      "    Merging JMeCormack@NACDS.org -> Jill McCormack (similarity: 1.000)\n",
      "    Merging Kathy Kulkarni -> KK@rubicondc.com (similarity: 1.000)\n",
      "    Merging kk@rubicondc.com -> Kathy Kulkarni (similarity: 1.000)\n",
      "    Merging William.Mallin@pharma.com -> William Mallin (similarity: 1.000)\n",
      "    Merging wssinc@verizon.net -> William S. Wilson (similarity: 1.000)\n",
      "    Merging Mary Menegay -> mmenegay@riteaid.com (similarity: 1.000)\n",
      "    Merging mmenegay@example.com -> mmenegay@riteaid.com (similarity: 1.000)\n",
      "    Merging mmenegay@example.com -> Mary Menegay (similarity: 1.000)\n",
      "    Merging mbennett@painfoundation.org -> Mary Bennett (similarity: 1.000)\n",
      "    Merging MARY STAPLES -> mstaples@NACDS.org (similarity: 1.000)\n",
      "    Merging Keith Nahigian -> keith@nahigianstrategies.com (similarity: 1.000)\n",
      "    Merging dgustin@example.com -> dave.gustin@mckesson.com (similarity: 1.000)\n",
      "    Merging Dave Gustin -> dave.gustin@mckesson.com (similarity: 1.000)\n",
      "    Merging dgustin@example.com -> Dave.Gustin@McKesson.com (similarity: 1.000)\n",
      "    Merging Dave Gustin -> Dave.Gustin@McKesson.com (similarity: 1.000)\n",
      "    Merging Dave Gustin -> dgustin@example.com (similarity: 1.000)\n",
      "    Merging Peter Kerrane -> peter.kerrane@credit-suisse.com (similarity: 1.000)\n",
      "    Merging PKounelis@amerisourcebergen.com -> Peter Kounelis (similarity: 1.000)\n",
      "    Merging Peter Ratycz -> pratvcz@discount-drugmart.com (similarity: 1.000)\n",
      "    Merging Joan Jerzak -> JJERZAK@medbd.ca.gov (similarity: 1.000)\n",
      "    Merging steven.mills@walgreens.com -> Steven Mills (similarity: 1.000)\n",
      "    Merging Steven A. Becker -> Steven.Becker@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Steven A Becker -> Steven.Becker@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Steven A Becker -> Steven A. Becker (similarity: 1.000)\n",
      "    Merging Steve.LaPierre@bsci.com -> Steven LaPierre (similarity: 1.000)\n",
      "    Merging steve@keysourcemedical.com -> Steven J. Cochrane (similarity: 1.000)\n",
      "    Merging Stephen McQueen -> stephen.mcqueen@walgreens.com (similarity: 1.000)\n",
      "    Merging Stephen Schmidt -> stephen.schmidt@mckesson.com (similarity: 1.000)\n",
      "    Merging Stephen Seid -> Stephenfsteve.seid@pharma.com (similarity: 1.000)\n",
      "    Merging Stephen.Seid@pharma.com -> Stephen Seid (similarity: 1.000)\n",
      "    Merging rxinventory@walgreens.com -> rxinventory (similarity: 1.000)\n",
      "    Merging Brian Budisak -> BBudisak@hlxusa.com (similarity: 1.000)\n",
      "    Merging Brian Shallenberger -> Brian.Shallenberger@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Brian Witte -> Brian.Witte@Andanet.com (similarity: 1.000)\n",
      "    Merging munroe.brian@endo.com -> Brian Munroe (similarity: 1.000)\n",
      "    Merging Munroe.Brian@Endo.com -> Brian Munroe (similarity: 1.000)\n",
      "    Merging munroe.bhan@endo.com -> Brian Munroe (similarity: 1.000)\n",
      "    Merging Brian McGovern -> brian.mcgovern@walgreens.com (similarity: 1.000)\n",
      "    Merging Jim.Rausch@Covidien.com -> Jim H. Rausch (similarity: 1.000)\n",
      "    Merging Jim H Rausch -> Jim H. Rausch (similarity: 1.000)\n",
      "    Merging Jim H Rausch -> Jim.Rausch@Covidien.com (similarity: 1.000)\n",
      "    Merging charles.forsaith@pharma.com -> Charles Forsaith (similarity: 1.000)\n",
      "    Merging Charles.Forsaith@pharma.com -> Charles Forsaith (similarity: 1.000)\n",
      "    Merging Christopher J. Casalenuovo -> ccasalenuovo@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Sheila Thelemann -> sthelemann@primetherapeutics.com (similarity: 1.000)\n",
      "    Merging  Sheila Thelemann -> sthelemann@primetherapeutics.com (similarity: 1.000)\n",
      "    Merging  Sheila Thelemann -> Sheila Thelemann (similarity: 1.000)\n",
      "    Merging Bob Clearwater -> bob.clearwater@mckesson.com (similarity: 1.000)\n",
      "    Merging andrea.best@abbott.com -> Andrea Best (similarity: 1.000)\n",
      "    Merging jmccormick@actavis.com -> Jinping McCormick (similarity: 1.000)\n",
      "    Merging JMCCORMICK@actavis.com -> Jinping McCormick (similarity: 1.000)\n",
      "    Merging JMCCORMICK@Actavis.com -> Jinping McCormick (similarity: 1.000)\n",
      "    Merging JinPing McCormick -> Jinping McCormick (similarity: 1.000)\n",
      "    Merging JinPing McCormick -> jmccormick@actavis.com (similarity: 1.000)\n",
      "    Merging JinPing McCormick -> JMCCORMICK@actavis.com (similarity: 1.000)\n",
      "    Merging JinPing McCormick -> JMCCORMICK@Actavis.com (similarity: 1.000)\n",
      "    Merging Bill Ratliff -> bill.ratliff@covidien.com (similarity: 1.000)\n",
      "    Merging Bill Ratliff -> bill.ratiiff@covidien.com (similarity: 1.000)\n",
      "    Merging Bill -> wssinc@veri20n.net (similarity: 1.000)\n",
      "    Merging bill.mahoney@mckesson.com -> Bill.Mahoney@pharma.com (similarity: 1.000)\n",
      "    Merging Bill Mahoney -> Bill.Mahoney@pharma.com (similarity: 1.000)\n",
      "    Merging Bill Mahoney -> bill.mahoney@mckesson.com (similarity: 1.000)\n",
      "    Merging Bill Burke -> BB@rubicondc.com (similarity: 1.000)\n",
      "    Merging Bill Ratliff -> Bill.Ratliff@Covidien.com (similarity: 1.000)\n",
      "    Merging Kyle J. Wright -> Kyle.J.Wright@usdoj.gov (similarity: 1.000)\n",
      "    Merging NLeitch9actavis.com -> Nathalie Leitch (similarity: 1.000)\n",
      "    Merging Victor Borelli -> Vlctor.borelli@covidien.com (similarity: 1.000)\n",
      "    Merging Victor M Borelli -> Victor.Borelli@Covidien.com (similarity: 1.000)\n",
      "    Merging Victor M. Borelli -> Victor.Borelli@Covidien.com (similarity: 1.000)\n",
      "    Merging Victor M. Borelli -> Victor M Borelli (similarity: 1.000)\n",
      "    Merging Victor Borelli -> victor.borelli@covidien.com (similarity: 1.000)\n",
      "    Merging Victor Borelli -> Victor.Borelli@covidien.com (similarity: 1.000)\n",
      "    Merging Kate M Muhlenkamp -> kmuhlenkamp@covidien.com (similarity: 1.000)\n",
      "    Merging Marilyn N Vaught -> Marilyn.Vaught@Covidien.com (similarity: 1.000)\n",
      "    Merging Stephanie Bucalo -> Stephanie.Bucalo@Covidien.com (similarity: 1.000)\n",
      "    Merging Stephanie Lai -> stephanie.lai@credit-suisse.com (similarity: 1.000)\n",
      "    Merging Morris Safdie -> morris@caligorrx.com (similarity: 1.000)\n",
      "    Merging dan.coughlin@walgreens.com -> Dan Coughlin (similarity: 1.000)\n",
      "    Merging Dan Howard -> Dan.Howard@hdsmith.com (similarity: 1.000)\n",
      "    Merging Dan Jefferies -> dan.jefferies@mckesson.com (similarity: 1.000)\n",
      "    Merging Dan Colucci -> Dan.Colucci@pharma.com (similarity: 1.000)\n",
      "    Merging Eileen.Spaulding@mallinckrodt.com -> Eileen L Spaulding (similarity: 1.000)\n",
      "    Merging Eileen L. Spaulding -> Eileen L Spaulding (similarity: 1.000)\n",
      "    Merging Eileen L. Spaulding -> Eileen.Spaulding@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging RichardW.Silbert@pharma.com -> Richard W. Silbert (similarity: 1.000)\n",
      "    Merging Richard Frank -> rfrank@ofwlaw.com (similarity: 1.000)\n",
      "    Merging Larry E Shaffer -> Larry.Shaffer@watson.com (similarity: 1.000)\n",
      "    Merging larry.shaffer@watson.com -> Larry E Shaffer (similarity: 1.000)\n",
      "    Merging Larry Hunley -> larry.hunley@mckesson.com (similarity: 1.000)\n",
      "    Merging Larry.P.Cote@usdoj.gov -> Larry P. Cote (similarity: 1.000)\n",
      "    Merging Master Data Group -> master.data.group@watson.com (similarity: 1.000)\n",
      "    Merging Judy L Callahan -> judy.callahan@watson.com (similarity: 1.000)\n",
      "    Merging Jeff W Burd -> jburd@gallaherswitzerland.ch (similarity: 1.000)\n",
      "    Merging jaltier2001@yahoo.com -> Jennifer Altier (similarity: 1.000)\n",
      "    Merging Jennifer.Buist@mallinckrodt.com -> Jennifer.Buist@covidien.com (similarity: 1.000)\n",
      "    Merging Jennifer M Buist -> Jennifer.Buist@covidien.com (similarity: 1.000)\n",
      "    Merging Jennifer M. Buist -> Jennifer.Buist@covidien.com (similarity: 1.000)\n",
      "    Merging Jennifer M Buist -> Jennifer.Buist@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Jennifer M. Buist -> Jennifer.Buist@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Jennifer M. Buist -> Jennifer M Buist (similarity: 1.000)\n",
      "    Merging Jennifer.Bullerdick@covidien.com -> Jennifer M. Bullerdick (similarity: 1.000)\n",
      "    Merging Jennifer M Bullerdick -> Jennifer M. Bullerdick (similarity: 1.000)\n",
      "    Merging Jennifer Speares -> jennifer.speares@searshc.com (similarity: 1.000)\n",
      "    Merging Jennifer M Bullerdick -> Jennifer.Bullerdick@covidien.com (similarity: 1.000)\n",
      "    Merging Jennifer Seiple -> jseiple@mastersra.com (similarity: 1.000)\n",
      "    Merging Jennifer.Erensen@pharma.com -> Jennifer Erensen (similarity: 1.000)\n",
      "    Merging Timothy.Foster@McKesson.com -> Timothy Foster (similarity: 1.000)\n",
      "    Merging Julie Khani -> JKhani@NACDS.org (similarity: 1.000)\n",
      "    Merging Julie Eddy -> JEddy@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Brenda.Rehkop@Covidien.com -> Brenda D. Rehkop (similarity: 1.000)\n",
      "    Merging Brenda D Rehkop -> Brenda D. Rehkop (similarity: 1.000)\n",
      "    Merging Brenda D Rehkop -> Brenda.Rehkop@Covidien.com (similarity: 1.000)\n",
      "    Merging AAprahamian@Actavis.com -> Ara Aprahamian RPh (similarity: 1.000)\n",
      "    Merging Ara.Aprahamian@McKesson.com -> Ara Aprahamian (similarity: 1.000)\n",
      "    Merging Rachelle Galant -> RGalant@actavis.com (similarity: 1.000)\n",
      "    Merging Joseph Millward -> Joseph.millward@gianteagle.com (similarity: 1.000)\n",
      "    Merging team -> Team (similarity: 1.000)\n",
      "    Merging Bruce -> Bruce.Russell@McKesson.com (similarity: 1.000)\n",
      "    Merging Bruce L Moskovitz -> bmoskovitz@example.com (similarity: 1.000)\n",
      "    Merging Bruce L. Moskovitz -> bmoskovitz@example.com (similarity: 1.000)\n",
      "    Merging Bruce L. Moskovitz -> Bruce L Moskovitz (similarity: 1.000)\n",
      "    Merging BGundy@amerisourcebergen.com -> Bruce Gundy (similarity: 1.000)\n",
      "    Merging Mark Hartman -> Mark.Hartman@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Mark.Geraci@pharma.com -> Mark Geraci (similarity: 1.000)\n",
      "    Merging Mark Chenoweth -> MChenoweth@WLF.org (similarity: 1.000)\n",
      "    Merging Mark Maney -> mark.maney@walgreens.com (similarity: 1.000)\n",
      "    Merging Beth Stafford -> BStafford@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging BLea@amerisourcebergen.com -> Beth Lea (similarity: 1.000)\n",
      "    Merging pkellv@hdmanet.org -> Patrick Kelly (similarity: 1.000)\n",
      "    Merging pkelly@hdmanet.org -> Patrick Kelly (similarity: 1.000)\n",
      "    Merging pkellv@hda.org -> Patrick Kelly (similarity: 1.000)\n",
      "    Merging pkellv@hda.org -> pkellv@hdmanet.org (similarity: 1.000)\n",
      "    Merging pkellv@hda.org -> pkelly@hdmanet.org (similarity: 1.000)\n",
      "    Merging Steve.Reardon@cardinalhealth.com -> Reardon, Steve (similarity: 1.000)\n",
      "    Merging John.Hansen@McKesson.com -> John Hansen (similarity: 1.000)\n",
      "    Merging John H. Stewart -> John.H.Stewart@pharma.com (similarity: 1.000)\n",
      "    Merging John Bohlinger -> john.bohlinger@mckesson.com (similarity: 1.000)\n",
      "    Merging John Gray -> jgray@hdmanet.org (similarity: 1.000)\n",
      "    Merging John Dzurenko -> JDzurenk@its.ini.com (similarity: 1.000)\n",
      "    Merging JDzurenk@its.jnj.com -> JDzurenk@its.ini.com (similarity: 1.000)\n",
      "    Merging John G Adams -> John.Adams@Covidien.com (similarity: 1.000)\n",
      "    Merging John Giglio -> JGiglio@painfoundation.org (similarity: 1.000)\n",
      "    Merging John.Duff@actavis.com -> John Duff (similarity: 1.000)\n",
      "    Merging JDzurenk@its.jnj.com -> John Dzurenko (similarity: 1.000)\n",
      "    Merging Douglas B. Farquhar -> DFarquhar@hpm.com (similarity: 1.000)\n",
      "    Merging Walmart -> WalMart (similarity: 1.000)\n",
      "    Merging Nancy Baran -> NBARAN@actavis.com (similarity: 1.000)\n",
      "    Merging Nancy Baran -> nbaran@actavis.com (similarity: 1.000)\n",
      "    Merging Russell Gasdia -> Russell.Gasdia@pharma.com (similarity: 1.000)\n",
      "    Merging Russell Portenoy, MD -> Russell Portenoy MD (similarity: 1.000)\n",
      "    Merging RPorteno@chpnet.org -> Russell Portenoy MD (similarity: 1.000)\n",
      "    Merging RPorteno@chpnet.org -> Russell Portenoy, MD (similarity: 1.000)\n",
      "    Merging Russell Portenoy -> RPortenoy@bethisraelny.org (similarity: 1.000)\n",
      "    Merging Robin Abrams -> Robin.Abrams@pharma.com (similarity: 1.000)\n",
      "    Merging Craig Morford -> craig.morford@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging CSchiavo@CVS.com -> Craig Schiavo (similarity: 1.000)\n",
      "    Merging cschiavo@cvscaremark.com -> Craig Schiavo (similarity: 1.000)\n",
      "    Merging cschiavo@cvscaremark.com -> CSchiavo@CVS.com (similarity: 1.000)\n",
      "    Merging Craig Engesser -> Craig.Engesser@pharma.com (similarity: 1.000)\n",
      "    Merging Edward Mahony -> Edward.Mahony@pharma.com (similarity: 1.000)\n",
      "    Merging Edward Bratton -> edward.bratton@walgreens.com (similarity: 1.000)\n",
      "    Merging ehazewski@amerisourcebergen.com -> Edward Hazewski (similarity: 1.000)\n",
      "    Merging Edward J. Svihra -> ed.svihra@walgreens.com (similarity: 1.000)\n",
      "    Merging Edward O'Brien -> e1 obrie(ï¿½wal-mart.com (similarity: 1.000)\n",
      "    Merging Gary.Cacciatore@cardinalhealth.com -> Gary Cacciatore (similarity: 1.000)\n",
      "    Merging Gary J Vorsanger -> gvorsanger@example.com (similarity: 1.000)\n",
      "    Merging Gary.Boggs@McKesson.com -> Gary Boggs (similarity: 1.000)\n",
      "    Merging Greg Thomas -> thomas.greg@endo.com (similarity: 1.000)\n",
      "    Merging Greg Halvacs -> Greg.Halvacs@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging George Chapman -> George.Chapman@wal-mart.com (similarity: 1.000)\n",
      "    Merging George L. Chapman, RPh, CHC -> George L Chapman, RPh, CHC (similarity: 1.000)\n",
      "    Merging geuson@hdsmith. com -> George L. Euson (similarity: 1.000)\n",
      "    Merging GEuson@hdsmith.com -> George Euson (similarity: 1.000)\n",
      "    Merging Brandon Wilkins -> Brandon.Wilkins@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging tbourque@cvscaremark.com -> Tom M. Bourque (similarity: 1.000)\n",
      "    Merging Tom.McDonald@McKesson.com -> Tom.McPonald@McKesson.cam (similarity: 1.000)\n",
      "    Merging Tom McDonald -> Tom.McPonald@McKesson.cam (similarity: 1.000)\n",
      "    Merging Tom McDonald -> Tom.McDonald@McKesson.com (similarity: 1.000)\n",
      "    Merging Tom Napoli -> Tom.Napoli@actavis.com (similarity: 1.000)\n",
      "    Merging Tom Palmer -> Tom.Palmer@Covidien.com (similarity: 1.000)\n",
      "    Merging Gail.Tetzlaff@mallinckrodt.com -> Gail.Tetzlaff@Covidien.com (similarity: 1.000)\n",
      "    Merging Gail S Tetzlaff -> Gail.Tetzlaff@Covidien.com (similarity: 1.000)\n",
      "    Merging Gail S. Tetzlaff -> Gail.Tetzlaff@Covidien.com (similarity: 1.000)\n",
      "    Merging gaiLtetzlaff@mallinckrodt.com -> Gail.Tetzlaff@Covidien.com (similarity: 1.000)\n",
      "    Merging Gail S Tetzlaff -> Gail.Tetzlaff@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Gail S. Tetzlaff -> Gail.Tetzlaff@mallinckrodt.com (similarity: 1.000)\n",
      "    Merging Gail S. Tetzlaff -> Gail S Tetzlaff (similarity: 1.000)\n",
      "    Merging gaiLtetzlaff@mallinckrodt.com -> Gail S Tetzlaff (similarity: 1.000)\n",
      "    Merging gaiLtetzlaff@mallinckrodt.com -> Gail S. Tetzlaff (similarity: 1.000)\n",
      "    Merging csteinberg@rcn.com -> Cindy Steinberg (similarity: 1.000)\n",
      "    Merging Andrew Moore -> andrew.moors@mckesson.com (similarity: 1.000)\n",
      "    Merging amoore@mckesson.com -> Andrew Moore (similarity: 1.000)\n",
      "    Merging anscholnick@painfoundation.org -> Andrew Scholnick (similarity: 1.000)\n",
      "    Merging andrew.bertagnolli@kp.org -> Andrew Bertagnolli (similarity: 1.000)\n",
      "    Merging Andrew J. O'Connor -> Andrew.OConnor@ropesgray.com (similarity: 1.000)\n",
      "    Merging Joe Lumpkin -> jae.lumpkin@mckesson.com (similarity: 1.000)\n",
      "    Merging joe.iumpkin@mckesson.com -> Joe Lumpkin (similarity: 1.000)\n",
      "    Merging Kim Grayson -> kimberly.grayson@mckesson.com (similarity: 1.000)\n",
      "    Merging Kim Lindell -> kllindell@ups.com (similarity: 1.000)\n",
      "    Merging DSmith@hdsmith.com -> Dale Smith (similarity: 1.000)\n",
      "    Merging Matt Boness -> matt.boness@mckesson.com (similarity: 1.000)\n",
      "    Merging EFischer@aolin.com -> Erica Fischer (similarity: 1.000)\n",
      "    Merging Rob Falb -> rob.falb@tevapharm.com (similarity: 1.000)\n",
      "    Merging Ken Nahigian -> ken@nahigianstrategies.com (similarity: 1.000)\n",
      "    Merging angela.feniger@parpharnn.com -> Angela Feniger (similarity: 1.000)\n",
      "    Merging angela.fenioer@parpharm.com -> Angela Feniger (similarity: 1.000)\n",
      "    Merging angela.fenioer@parpharm.com -> angela.feniger@parpharnn.com (similarity: 1.000)\n",
      "    Merging Zach.Hall@ey.com -> Zach T Hall (similarity: 1.000)\n",
      "    Merging Chris Zimmerman -> CZimmerman@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Chris -> chall@riteaid.com (similarity: 1.000)\n",
      "    Merging ChrisPrieve@amerisourcebergen.com -> Chris Prieve (similarity: 1.000)\n",
      "    Merging tamarasa(2>verizon.net> -> Tamara Sloan Anderson (similarity: 1.000)\n",
      "    Merging tamarasa@verizon.net -> Tamara Sloan Anderson (similarity: 1.000)\n",
      "    Merging tamarasa@verizon.net -> tamarasa(2>verizon.net> (similarity: 1.000)\n",
      "    Merging Allison Liz -> Allison, Liz (similarity: 1.000)\n",
      "    Merging atuszynski@hdmanet.org -> Allison Tuszynski (similarity: 1.000)\n",
      "    Merging Allison Wiley -> awiley@hdmanet.org (similarity: 1.000)\n",
      "    Merging Dempsey, Michele -> Dempsey Michele (similarity: 1.000)\n",
      "    Merging SMITH DRUG -> Smith drug (similarity: 1.000)\n",
      "    Merging pritter@hdmanet.org -> Pam Ritter (similarity: 1.000)\n",
      "    Merging Pam Holohan -> Pam.Holohan@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Allyne.Montano@Covidien.com -> Allyne Montano (similarity: 1.000)\n",
      "    Merging President -> president (similarity: 1.000)\n",
      "    Merging Demir Bingol -> Bingol.Demir@Endo.com (similarity: 1.000)\n",
      "    Merging Annette Eyer -> aeyer@cullarigroup.com (similarity: 1.000)\n",
      "    Merging Sandy Marks -> Sandy.Marks@ama-assn.org (similarity: 1.000)\n",
      "    Merging Lynn Dacunha -> Lynn DaCunha (similarity: 1.000)\n",
      "    Merging Michael.Mone@cardinalhealth.com -> Mone, Michael (similarity: 1.000)\n",
      "    Merging CommunityRelations@cardinalhealth.com -> GMB-DUB-CommunityRelations (similarity: 1.000)\n",
      "    Merging jbuck@hsc.wvu.edu -> Joy Buck (similarity: 1.000)\n",
      "    Merging Joy M Myers -> myersi@gao.gov (similarity: 1.000)\n",
      "    Merging Patricia Wilkinson ->  pwilkinson@example.com (similarity: 1.000)\n",
      "    Merging pwilkinson@example.com -> Patricia Wilkinson (similarity: 1.000)\n",
      "    Merging Jeni Dominguez -> jeni.dominguez@mckesson.com (similarity: 1.000)\n",
      "    Merging Ron Duvall -> ronnie.duvall@mckesson.com (similarity: 1.000)\n",
      "    Merging Ron Paul -> Ron-Paul (similarity: 1.000)\n",
      "    Merging Ron.Buzzeo@dendrite.com -> Ron Buzzeo (similarity: 1.000)\n",
      "    Merging rkuntz@its.jnj.com -> Ron Kuntz (similarity: 1.000)\n",
      "    Merging rkuntz@its.inj.com -> Ron Kuntz (similarity: 1.000)\n",
      "    Merging rkuntz@its.inj.com -> rkuntz@its.jnj.com (similarity: 1.000)\n",
      "    Merging Duncan Falco -> duncan.falco@mckesson.com (similarity: 1.000)\n",
      "    Merging Brett Harrop -> brett.harrop@mckesson.com (similarity: 1.000)\n",
      "    Merging Todd Kleinow -> todd.kleinow@mckesson.com (similarity: 1.000)\n",
      "    Merging Todd Schrick -> todd.schrick@mckesson.com (similarity: 1.000)\n",
      "    Merging Todd Roahrig -> todd.roahrig@gianteagle.com (similarity: 1.000)\n",
      "    Merging Todd.Cameron@cardinalhealth.com -> Todd Cameron (similarity: 1.000)\n",
      "    Merging Todd Smith -> TS@rubicondc.com (similarity: 1.000)\n",
      "    Merging Todd Askew -> Todd.Askew@ama-assn.org (similarity: 1.000)\n",
      "    Merging Todd Steffen -> todd.steffen@walgreens.com (similarity: 1.000)\n",
      "    Merging Jake Kramer -> jake.kramer@mckesson.com (similarity: 1.000)\n",
      "    Merging Ruben Vital -> ruben.vital@mckesson.com (similarity: 1.000)\n",
      "    Merging JeffL Marshall -> jeffl.marshall@mckesson.com (similarity: 1.000)\n",
      "    Merging Bonnie I New -> Bonnie.New@Covidien.com (similarity: 1.000)\n",
      "    Merging Bonnie Weissfeld -> BONNIE WEISSFELD (similarity: 1.000)\n",
      "    Merging Pharmacy Supervisors -> pharmacysupervisors@walgreens.com (similarity: 1.000)\n",
      "    Merging pharmacy managers -> Pharmacy Managers (similarity: 1.000)\n",
      "    Merging Sophia Lai -> slai@riteaid.com (similarity: 1.000)\n",
      "    Merging His -> his (similarity: 1.000)\n",
      "    Merging keyserling@njpco.org -> Jonathan Keyserling (similarity: 1.000)\n",
      "    Merging jkeyserling@nhpco.org -> Jonathan Keyserling (similarity: 1.000)\n",
      "    Merging Jonathan Wale -> JWale@gallaherswitzerland.ch (similarity: 1.000)\n",
      "    Merging jkeyserling@nhpco.org -> keyserling@njpco.org (similarity: 1.000)\n",
      "    Merging Jenna Nichols -> jenna.nichols@mckesson.com (similarity: 1.000)\n",
      "    Merging Jenna Vancura -> jvancura@golinHarris.com (similarity: 1.000)\n",
      "    Merging BWynne@appliedcme.com -> Barbara Jean Wynne (similarity: 1.000)\n",
      "    Merging bgordon@icheip.org -> Barbara Gordon (similarity: 1.000)\n",
      "    Merging Barbara A. Martin -> barbara.martin@walgreens.com (similarity: 1.000)\n",
      "    Merging Giselle.Issa@pharma.com -> Giselle Issa (similarity: 1.000)\n",
      "    Merging Product.ReleaseAlert.Notification@actavis.com -> Actavis (similarity: 1.000)\n",
      "    Merging Spaulding, Eileen L -> Spaulding, Eileen L. (similarity: 1.000)\n",
      "    Merging Merritt, Elaine -> Merritt Elaine (similarity: 1.000)\n",
      "    Merging Levitt, Michael -> Levitt Michael (similarity: 1.000)\n",
      "    Merging Dysart, Art -> Dysart Art (similarity: 1.000)\n",
      "    Merging Lopez, Andres -> Lopez Andres (similarity: 1.000)\n",
      "    Merging Griffith, Mike -> Griffith Mike (similarity: 1.000)\n",
      "    Merging Mincarelli, Alfred -> Mincarelli Alfred (similarity: 1.000)\n",
      "    Merging Debbie Garza -> debbie.garza@walgreens.com (similarity: 1.000)\n",
      "    Merging Neil Beitz -> neil.beitz@walgreens.com (similarity: 1.000)\n",
      "    Merging Andy.Grant@cardinalhealth.com -> Andy Grant (similarity: 1.000)\n",
      "    Merging apalmer@riteaid.com -> Andy Palmer (similarity: 1.000)\n",
      "    Merging Melissa Evangelista -> melissa.evangelista@mckesson.com (similarity: 1.000)\n",
      "    Merging sue.thoss@walgreens.com -> Sue Thoss (similarity: 1.000)\n",
      "    Merging Nate Hartle -> nhartle@mckesson.com (similarity: 1.000)\n",
      "    Merging nate.hartle@mckesson.com -> Nate Hartle (similarity: 1.000)\n",
      "    Merging Jane.Williams@covidien.com -> Jane Williams (similarity: 1.000)\n",
      "    Merging udelllawoffice@pharma.com -> Howard Udell (similarity: 1.000)\n",
      "    Merging Tara Brolly -> broilv taraOallergan.com (similarity: 1.000)\n",
      "    Merging Tara Chapman -> chapman .tara@endo. com (similarity: 1.000)\n",
      "    Merging Eric Cherveny -> ECherveny@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging EMartin@amerisourcebergen.com -> Eric Martin (similarity: 1.000)\n",
      "    Merging Eric Brantley -> EBrantley@QualiTestRx.com (similarity: 1.000)\n",
      "    Merging EBrantley@OualiTestRx.com -> EBrantley@QualiTestRx.com (similarity: 1.000)\n",
      "    Merging ebrantlev@qualitestrx.com -> Eric Brantley (similarity: 1.000)\n",
      "    Merging EBrantley@OualiTestRx.com -> Eric Brantley (similarity: 1.000)\n",
      "    Merging ebrantley@qualitestrx.com -> Eric Brantley (similarity: 1.000)\n",
      "    Merging EJuhl@NACDS.org -> Eric Juhl (similarity: 1.000)\n",
      "    Merging EBrantley@OualiTestRx.com -> ebrantlev@qualitestrx.com (similarity: 1.000)\n",
      "    Merging ebrantley@qualitestrx.com -> EBrantley@OualiTestRx.com (similarity: 1.000)\n",
      "    Merging mpeguri@amerisourcebergen.com -> Maurizio Peguri (similarity: 1.000)\n",
      "    Merging Christina Cognata Smith -> csmith17@janus.jnj.com (similarity: 1.000)\n",
      "    Merging Purdue Pharma, LP. -> Purdue Pharma (similarity: 1.000)\n",
      "    Merging Purdue Team -> Purdue team (similarity: 1.000)\n",
      "    Merging kstrauser@highwaterpartners.net -> Kathleen Strauser (similarity: 1.000)\n",
      "    Merging Sullivan.Kathleen@Eiido.com -> Kathleen Sullivan (similarity: 1.000)\n",
      "    Merging Carolyn.McPherson@cardinalhealth.com -> Carolyn McPherson (similarity: 1.000)\n",
      "    Merging Carolyn Grant -> carolyn.grant@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Nicole Mann -> nicole.mann@tevapharm.com (similarity: 1.000)\n",
      "    Merging Dennis Wiesner -> wiesner.dennis@heb.com (similarity: 1.000)\n",
      "    Merging aducca@hda.org -> aducca@hdmanet.org (similarity: 1.000)\n",
      "    Merging Anita ducca -> aducca@hdmanet.org (similarity: 1.000)\n",
      "    Merging aducca@hdmanet,org -> aducca@hdmanet.org (similarity: 1.000)\n",
      "    Merging aducca@painfoundation.org -> aducca@hdmanet.org (similarity: 1.000)\n",
      "    Merging Anita Ducca -> aducca@hdmanet.org (similarity: 1.000)\n",
      "    Merging Anita ducca -> aducca@hda.org (similarity: 1.000)\n",
      "    Merging aducca@hdmanet,org -> aducca@hda.org (similarity: 1.000)\n",
      "    Merging aducca@painfoundation.org -> aducca@hda.org (similarity: 1.000)\n",
      "    Merging Anita Ducca -> aducca@hda.org (similarity: 1.000)\n",
      "    Merging aducca@hdmanet,org -> Anita ducca (similarity: 1.000)\n",
      "    Merging aducca@painfoundation.org -> Anita ducca (similarity: 1.000)\n",
      "    Merging Anita Ducca -> Anita ducca (similarity: 1.000)\n",
      "    Merging aducca@painfoundation.org -> aducca@hdmanet,org (similarity: 1.000)\n",
      "    Merging Anita Ducca -> aducca@hdmanet,org (similarity: 1.000)\n",
      "    Merging Anita Ducca -> aducca@painfoundation.org (similarity: 1.000)\n",
      "    Merging ecampbell@example.com -> Elizabeth Campbell (similarity: 1.000)\n",
      "    Merging Elizabeth.Adams@pharma.com -> Elizabeth Adams (similarity: 1.000)\n",
      "    Merging Elizabeth S. Adams -> elizabeth.adams@pharma.com (similarity: 1.000)\n",
      "    Merging egallenagh@hda.org -> Elizabeth Gallenagh (similarity: 1.000)\n",
      "    Merging Elizabeth A Lankford -> elankford@hdmanet.org (similarity: 1.000)\n",
      "    Merging Shirlene.Justus@cardinalhealth.com -> Shirlene.Justus@cardinal.com (similarity: 1.000)\n",
      "    Merging Fred Ottolino -> fred.ottolino@publix.com (similarity: 1.000)\n",
      "    Merging rv1Guerreiro@amerisourcebergen.com -> Marcelino Guerreiro (similarity: 1.000)\n",
      "    Merging Tracy Plouffe -> TPIouffe@rdcdrug.com (similarity: 1.000)\n",
      "    Merging sjacobson@riteaid.com -> Scott Jacobson (similarity: 1.000)\n",
      "    Merging smelvill@cephalon.com -> Scott Melville (similarity: 1.000)\n",
      "    Merging smelville@cephalon.com -> Scott Melville (similarity: 1.000)\n",
      "    Merging melville@hdmanet.org -> Scott Melville (similarity: 1.000)\n",
      "    Merging melville@hdmanet.org -> smelvill@cephalon.com (similarity: 1.000)\n",
      "    Merging melville@hdmanet.org -> smelville@cephalon.com (similarity: 1.000)\n",
      "    Merging Alvey Squires -> asquires@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Alvey.Squires@cardinalhealth.com -> Alvey Squires (similarity: 1.000)\n",
      "    Merging Thomas.DeGemmis@cardinalhealth.com -> Thomas DeGemmis (similarity: 1.000)\n",
      "    Merging Sandro.Schmidt@cardinalhealth.com -> Sandro Schmidt (similarity: 1.000)\n",
      "    Merging erik.lilje@cardinalhealth.com -> Erik Lilje (similarity: 1.000)\n",
      "    Merging Erik.Lilje@cardinalhealth.com -> Erik Lilje (similarity: 1.000)\n",
      "    Merging Jimmy.Neil@cardinalhealth.com -> Jimmy Neil (similarity: 1.000)\n",
      "    Merging Jimmy Fokas -> jfokas@bakerlaw.com (similarity: 1.000)\n",
      "    Merging Ronna Hauser -> rhauser@ncpanet.org (similarity: 1.000)\n",
      "    Merging awelch champion@compassionandchoices.org -> Aimee Welch Champion (similarity: 1.000)\n",
      "    Merging Aimee Welch champion -> Aimee Welch Champion (similarity: 1.000)\n",
      "    Merging Aimee Cooper -> Aimee.Cooper@pan3harm.com (similarity: 1.000)\n",
      "    Merging Aimee Welch champion -> awelch champion@compassionandchoices.org (similarity: 1.000)\n",
      "    Merging alan.mcember@abbvie.com -> Alan McEmber (similarity: 1.000)\n",
      "    Merging Alan.Must@pharma.com -> Alan Must (similarity: 1.000)\n",
      "    Merging astone@ons.org -> Alec Stone (similarity: 1.000)\n",
      "    Merging Gina Limer -> gina.limer@pharma.com (similarity: 1.000)\n",
      "    Merging Gina.Limer@pharma.com -> Gina Limer (similarity: 1.000)\n",
      "    Merging Gina.Barbarotto@pharma.com -> Gina Barbarotto (similarity: 1.000)\n",
      "    Merging Emily Schultz -> Emily.Schultz@Andanet.com (similarity: 1.000)\n",
      "    Merging Debra Barrett -> debra.barrett@tevapharm.com (similarity: 1.000)\n",
      "    Merging Denny Murray, Pharm. D. -> Denny Murray, Pharm. D (similarity: 1.000)\n",
      "    Merging Denny Murray, Pharm, D -> Denny Murray, Pharm. D (similarity: 1.000)\n",
      "    Merging Denny Murray, Pharm, D -> Denny Murray, Pharm. D. (similarity: 1.000)\n",
      "    Merging denman.murray@walgreens.com -> Denman Murray (similarity: 1.000)\n",
      "    Merging Denman D. Murray Jr -> Denman D. Murray Jr. (similarity: 1.000)\n",
      "    Merging Tasha.Polster@walgreens.com -> Tasha Polster (similarity: 1.000)\n",
      "    Merging Nicholas.Rausch@cardinalhealth.com -> Nicholas Rausch (similarity: 1.000)\n",
      "    Merging Diane Riggs -> diane.riggs@cardinal.com (similarity: 1.000)\n",
      "    Merging Diane Darvey -> ddarvey@NACDS.org (similarity: 1.000)\n",
      "    Merging Burt Rosen -> Burt.Rosen@pharma.com (similarity: 1.000)\n",
      "    Merging burt.rosen@pharma.cGm -> Burt.Rosen@pharma.com (similarity: 1.000)\n",
      "    Merging burt.rosen@pharma.cGm -> Burt Rosen (similarity: 1.000)\n",
      "    Merging Gilberto Quintero -> gilberto.quintero@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Connie Woodburn -> Connie.Woodburn@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging wrowe@painfoundation.org -> Will Rowe (similarity: 1.000)\n",
      "    Merging Jodi.Avergun@cwt.com -> Jodi Avergun (similarity: 1.000)\n",
      "    Merging Rita Norton -> RNorton@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging rnorton@amerisourcebergen.com -> Rita Norton (similarity: 1.000)\n",
      "    Merging You -> you (similarity: 1.000)\n",
      "    Merging tomson.george@walgreens.com -> Tomson George (similarity: 1.000)\n",
      "    Merging suzanne.hansen@walgreens.com -> Suzanne Hansen (similarity: 1.000)\n",
      "    Merging Hazewski Edward -> EHazewski@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Hazewski, Edward -> EHazewski@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Hazewski.Edward@example.invalid -> EHazewski@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Hazewski, Edward -> Hazewski Edward (similarity: 1.000)\n",
      "    Merging Hazewski.Edward@example.invalid -> Hazewski Edward (similarity: 1.000)\n",
      "    Merging Hazewski.Edward@example.invalid -> Hazewski, Edward (similarity: 1.000)\n",
      "    Merging Kristen LaRose Freitas -> kfreitas@hdmanet.org (similarity: 1.000)\n",
      "    Merging Kristen Freitas -> kfreitas@hda.org (similarity: 1.000)\n",
      "    Merging Janet McUisky -> Janet McUIsky (similarity: 1.000)\n",
      "    Merging Janet M Hart -> jhart@example.org (similarity: 1.000)\n",
      "    Merging HartOhart@riteaid.com -> jhart@example.org (similarity: 1.000)\n",
      "    Merging HartOhart@riteaid.com -> Janet M Hart (similarity: 1.000)\n",
      "    Merging HDMA Staff -> HDMA staff (similarity: 1.000)\n",
      "    Merging Kian L. Kazemi -> Kian.Kazemi@covidien.com (similarity: 1.000)\n",
      "    Merging Kian.Kazemi@mallinckrodt.com -> Kian.Kazemi@covidien.com (similarity: 1.000)\n",
      "    Merging Kian.Kazemi@mallinckrodt.com -> Kian L. Kazemi (similarity: 1.000)\n",
      "    Merging Walt Kaczmarek -> Walt.Kaczmarek@covidien.com (similarity: 1.000)\n",
      "    Merging Ginger Collier -> Ginger.Collier@covidien.com (similarity: 1.000)\n",
      "    Merging Marc Montgomery -> Marc.Montgomery@Covidien.com (similarity: 1.000)\n",
      "    Merging bdayton@aholdusa.com -> Bradley Dayton (similarity: 1.000)\n",
      "    Merging Garth -> garth (similarity: 1.000)\n",
      "    Merging Rich -> rich (similarity: 1.000)\n",
      "    Merging Solana.Shaw@pharma.com -> Solana Shaw (similarity: 1.000)\n",
      "    Merging solana.shaw@example.com -> Solana Shaw (similarity: 1.000)\n",
      "    Merging solana.shaw@example.com -> Solana.Shaw@pharma.com (similarity: 1.000)\n",
      "    Merging Albert F. Schuster -> aschuster@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging Bishop, Steve -> Bishop Steve (similarity: 1.000)\n",
      "    Merging omcmahon@riteaid.com -> Owen P McMahon (similarity: 1.000)\n",
      "    Merging LaDonna.Steiner@pharma.com -> LaDonna Steiner (similarity: 1.000)\n",
      "    Merging cassi.baker@cardinal.com -> Cassi Baker (similarity: 1.000)\n",
      "    Merging Cassi.Baker@cardinalhealth.com -> Cassi Baker (similarity: 1.000)\n",
      "    Merging Cassi.Baker@cardinalhealth.com -> cassi.baker@cardinal.com (similarity: 1.000)\n",
      "    Merging Nic Kipke -> kipke@kipke.com (similarity: 1.000)\n",
      "    Merging Sylvia Trujillo -> Sylvia.Trujillo@ama-assn.org (similarity: 1.000)\n",
      "    Merging jcosgrove@hdmanet.org -> jcosgrove@hda.org (similarity: 1.000)\n",
      "    Merging icosgrove@hdmanet.org -> jcosgrove@hda.org (similarity: 1.000)\n",
      "    Merging Jewelyn Cosgrove -> jcosgrove@hda.org (similarity: 1.000)\n",
      "    Merging icosqrove@hdmanet.org -> jcosgrove@hda.org (similarity: 1.000)\n",
      "    Merging Jewelyn Cosgrove -> jcosgrove@hdmanet.org (similarity: 1.000)\n",
      "    Merging Jewelyn Cosgrove -> icosgrove@hdmanet.org (similarity: 1.000)\n",
      "    Merging icosqrove@hdmanet.org -> Jewelyn Cosgrove (similarity: 1.000)\n",
      "    Merging achrisney@painfoundation.org -> Adam Chrisney (similarity: 1.000)\n",
      "    Merging Adam.Chrisney@ppsv.com -> Adam Chrisney (similarity: 1.000)\n",
      "    Merging adClark@painfoundation.org -> Adam Clark (similarity: 1.000)\n",
      "    Merging adam.clark@laf.org -> Adam Clark (similarity: 1.000)\n",
      "    Merging Adam.Chrisney@ppsv.com -> achrisney@painfoundation.org (similarity: 1.000)\n",
      "    Merging adam.clark@laf.org -> adClark@painfoundation.org (similarity: 1.000)\n",
      "    Merging Rebecca Kirch -> RKirch@CANCER.ORG (similarity: 1.000)\n",
      "    Merging Shaw Solana -> Shaw, Solana (similarity: 1.000)\n",
      "    Merging Saurabh Jang -> saurabh.jang@credit-suisse.com (similarity: 1.000)\n",
      "    Merging amgilson@wisc.edu -> Aaron Gilson (similarity: 1.000)\n",
      "    Merging agilson@example.com -> Aaron Gilson (similarity: 1.000)\n",
      "    Merging agilson@painfoundation.org -> Aaron Gilson (similarity: 1.000)\n",
      "    Merging agilson@example.com -> amgilson@wisc.edu (similarity: 1.000)\n",
      "    Merging agilson@painfoundation.org -> amgilson@wisc.edu (similarity: 1.000)\n",
      "    Merging agilson@painfoundation.org -> agilson@example.com (similarity: 1.000)\n",
      "    Merging rkohn@its.jnj.com -> Robyn M. Kohn (similarity: 1.000)\n",
      "    Merging tasha.polster@walgreens.com -> Natasha Polster (similarity: 1.000)\n",
      "    Merging Director of DEA Compliance -> Director of DEA. Compliance (similarity: 1.000)\n",
      "    Merging Miranda.Burris@walmart.com -> Miranda Johnson (similarity: 1.000)\n",
      "    Merging chuck.greener@walgreens.com -> Chuck Greener (similarity: 1.000)\n",
      "    Merging CReed@amerisourcebergen.com -> Chuck Reed (similarity: 1.000)\n",
      "    Merging Molly Hughes -> molly.hughes@cardinalhealth.com (similarity: 1.000)\n",
      "    Merging Vicki Mangus -> vicki.mangus@andanet.com (similarity: 1.000)\n",
      "    Merging Pamela A. Ritter -> pritter@hdmariet.org (similarity: 1.000)\n",
      "    Merging Pamela.Bennett@pharma.com -> Pamela Bennett (similarity: 1.000)\n",
      "    Merging Anne Johnson -> ajohnson@hdmanet.org (similarity: 1.000)\n",
      "    Merging Anne Oswalt -> AOswalt@amerisourcebergen.com (similarity: 1.000)\n",
      "    Merging kmit@ix.netcom.com -> Barry Eliot Cole (similarity: 1.000)\n",
      "    Merging keysha brooks-coley -> Keysha Brooks-Coley (similarity: 1.000)\n",
      "    Merging KLunner@APHANET.ORG -> Kristina Lunner (similarity: 1.000)\n",
      "    Merging Kristina Bezares ->  Kristina Bezares (similarity: 1.000)\n",
      "    Merging mbrown@painfoundation.org -> Micke Brown (similarity: 1.000)\n",
      "    Merging MChristopher@practicalbioethics.org -> Myra Christopher (similarity: 1.000)\n",
      "    Merging MDempse3@its.jnj.com -> MDempse3@gfj.example (similarity: 1.000)\n",
      "    Merging mdempse3@its.ini.com -> MDempse3@gfj.example (similarity: 1.000)\n",
      "    Merging Michele Dempsey -> MDempse3@gfj.example (similarity: 1.000)\n",
      "    Merging MDempse3@its.inj.com -> MDempse3@gfj.example (similarity: 1.000)\n",
      "    Merging mdempsey@ITS.JNJ.COM -> MDempse3@gfj.example (similarity: 1.000)\n",
      "    Merging mdempse3@its.ini.com -> MDempse3@its.jnj.com (similarity: 1.000)\n",
      "    Merging Michele Dempsey -> MDempse3@its.jnj.com (similarity: 1.000)\n",
      "    Merging MDempse3@its.inj.com -> MDempse3@its.jnj.com (similarity: 1.000)\n",
      "    Merging Michele Dempsey -> mdempse3@its.ini.com (similarity: 1.000)\n",
      "    Merging MDempse3@its.inj.com -> mdempse3@its.ini.com (similarity: 1.000)\n",
      "    Merging mdempsey@ITS.JNJ.COM -> mdempse3@its.ini.com (similarity: 1.000)\n",
      "    Merging MDempse3@its.inj.com -> Michele Dempsey (similarity: 1.000)\n",
      "    Merging mdempsey@ITS.JNJ.COM -> Michele Dempsey (similarity: 1.000)\n",
      "    Merging mdempsey@ITS.JNJ.COM -> MDempse3@its.inj.com (similarity: 1.000)\n",
      "    Merging Carol Sherman-Hynes -> Carol Sherman - Hynes (similarity: 1.000)\n",
      "    Merging Carol Kelly -> CKelly@NACDS.org (similarity: 1.000)\n",
      "    Merging Colleen.McGinn@tevapharm.com -> Colleen McGinn (similarity: 1.000)\n",
      "    Merging elva.ramsaran@mallinckrodt.com -> Elva Ramsaran (similarity: 1.000)\n",
      "    Merging Margaret Feltz -> Margaret.Feltz@pharma.com (similarity: 1.000)\n",
      "    Merging sean.callinicos@cardinalhealth.com -> Sean Callinicos (similarity: 1.000)\n",
      "    Merging edgar.rivera@accenture.com -> Edgar Rivera (similarity: 1.000)\n",
      "    Merging SMani1@its.ini.com -> Sudha Mani (similarity: 1.000)\n",
      "    Merging smani@ITS.JNJ.COM -> Sudha Mani (similarity: 1.000)\n",
      "    Merging smani@ITS.JNJ.COM -> SMani1@its.ini.com (similarity: 1.000)\n",
      "    Merging Katrina Purifoy -> pkatrina@ITS.JNJ.com (similarity: 1.000)\n",
      "    Merging pkatrina@ITS.JNJ.COM -> Katrina Purifoy (similarity: 1.000)\n",
      "    Merging kpurifoy@ITS.JNJ.COM -> Katrina Purifoy (similarity: 1.000)\n",
      "    Merging rbruno@its.inj.com -> rbruno@its.ini.com (similarity: 1.000)\n",
      "    Merging JDzurenk@its.inj.com -> JDzurenk@its.jni.com (similarity: 1.000)\n",
      "    Merging wchov@ITS.JNJ.COM -> Wai Yue Choy (similarity: 1.000)\n",
      "    Merging nrebeco@actavis.com -> Noemi Rebeco (similarity: 1.000)\n",
      "    Merging Kristine Atwell -> kristine.atwelI@waIgreens.corn (similarity: 1.000)\n",
      "    Merging kristine.atwell@walgreens.com -> kristine.atwelI@waIgreens.corn (similarity: 1.000)\n",
      "    Merging katwell@walgreens.com -> kristine.atwelI@waIgreens.corn (similarity: 1.000)\n",
      "    Merging kristine.atwell@walgreens.com -> Kristine Atwell (similarity: 1.000)\n",
      "    Merging katwell@walgreens.com -> Kristine Atwell (similarity: 1.000)\n",
      "    Merging justin.joseph@walgreens.com -> Justin Joseph (similarity: 1.000)\n",
      "    Merging Seid, Stephen -> Seid Stephen (similarity: 1.000)\n",
      "    Merging Tracey Hernandez -> tracey.hernandez@dea.gov (similarity: 1.000)\n",
      "    Merging all -> All (similarity: 1.000)\n",
      "    Merging Aaron.Graham@pharma.com -> Graham, Aaron (similarity: 1.000)\n",
      "    Merging AmerisourceBergen Corporation -> AmerisourceBergen (similarity: 1.000)\n",
      "    Merging barb.martin@walgreens.com -> Barb Martin (similarity: 1.000)\n",
      "    Merging Kimberley.Tiller@pharmaxom -> Kimberley Tiller (similarity: 1.000)\n",
      "    Merging Kimberley.Tiller@pharma.com -> Kimberley Tiller (similarity: 1.000)\n",
      "    Merging Kimberley.Tiller@pharma.com -> Kimberley.Tiller@pharmaxom (similarity: 1.000)\n",
      "    Merging lennie duensing -> Lennie Duensing (similarity: 1.000)\n",
      "    Merging  Meredith Nguyen -> Meredith Nguyen (similarity: 1.000)\n",
      "    Merging  Meredith Y. Smith -> Meredith Y. Smith (similarity: 1.000)\n",
      "    Merging Meredith Smith ->  Meredith Smith (similarity: 1.000)\n",
      "    Merging Stewart B. Leavitt -> stew202@comcast.net (similarity: 1.000)\n",
      "    Merging ashiey.myracle@rmpdc.org -> Ashley Myracle (similarity: 1.000)\n",
      "    Merging Dana Lichtenberg -> Dana.Lichtenberg@ama-assn.org (similarity: 1.000)\n",
      "    Merging fqureshi@hda.org -> Farah Qureshi (similarity: 1.000)\n",
      "    Merging linden.barber@quarles.com -> Linden Barber (similarity: 1.000)\n",
      "    Merging Garry Hodge -> garry.hodge@walgreens.com (similarity: 1.000)\n",
      "    Merging hru -> HRU (similarity: 1.000)\n",
      "    Merging Dolly Judge -> dolly.judge@pfizer.com (similarity: 1.000)\n",
      "    Merging Gloria Acevedo -> gloria.acevedo@henryschein.com (similarity: 1.000)\n",
      "    Merging Bethany Seabolt -> bseabolt@transcept.com (similarity: 1.000)\n",
      "    Merging Gil Genn -> gil.genn@capitolhillstrategicadvocates.com (similarity: 1.000)\n",
      "    Merging Marva Gray -> Marva.Gray@tevapharm.com (similarity: 1.000)\n",
      "    Merging Aiken Hackett -> Aiken.Hackett@ama-assn.org (similarity: 1.000)\n",
      "    Merging congressman Loebsack -> Congressman Loebsack (similarity: 1.000)\n",
      "    Merging Engesser, Craig -> Engesser@purduedomain (similarity: 1.000)\n",
      "    Merging Barbarotto, Gina -> barbagi@pharma.com (similarity: 1.000)\n",
      "    Merging Saeed.Motahari@pharma.com -> Saeed Motahari (similarity: 1.000)\n",
      "    Merging Raul.Damas@pharma.com -> Raul Damas (similarity: 1.000)\n",
      "    Merging Brooke Leverett -> brooke.patterson@walmart.com (similarity: 1.000)\n",
      "    Merging Juliana.Gittler@pharma.com -> Juliana Gittler (similarity: 1.000)\n",
      "    Merging adrian.durbin@mckesson.com -> Adrian Durbin (similarity: 1.000)\n",
      "    Merging Izabela Strzalkowski -> lstrzalkowski@Connect2amc.com (similarity: 1.000)\n",
      "    Merging UPS -> JMPage@ups.com (similarity: 1.000)\n",
      "    Merging Terrance Woodworth -> twoodworth@thedcag.com (similarity: 1.000)\n",
      "    Merging Henry Schein -> Henry Schein, Inc. (similarity: 1.000)\n",
      "    Merging Iiwiii.X.Reaves@usdoi.gov -> Irvin Reaves (similarity: 1.000)\n",
      "    Merging Kermit Crawford -> kermit.crawford@walgreens.com (similarity: 1.000)\n",
      "    Merging Mayur Tailor -> mayur.tailor@walgreens.com (similarity: 1.000)\n",
      "    Merging Brit Videbeck -> brit.videbeck@walgreens.com (similarity: 1.000)\n",
      "    Merging Brent Bumpas -> bumpas.brent@endo.com (similarity: 1.000)\n",
      "  âœ“ Successfully merged 808 person node(s)\n",
      "\n",
      "[3/4] Resolving Organizations (threshold=0.9)...\n",
      "  Found 50 potential organization duplicates\n",
      "    Merging 'us department of justice' -> 'u s department of justice' (similarity: 0.980)\n",
      "    Merging 'covidien mallinckrodt pharmaceuticals' -> 'covidien mallinckrodt pharmaceutical products' (similarity: 0.902)\n",
      "    Merging 'walgreens' -> 'walgreen' (similarity: 0.941)\n",
      "    Merging 'mallinckrodt pharmaceutical generics' -> 'mallinckrodt dosage pharmaceuticals generics' (similarity: 0.900)\n",
      "    Merging 'covidien mallinckrodt pharmaceuticals generics' -> 'covidien mallinckrodt pharmaceutical generics' (similarity: 0.989)\n",
      "    Merging 'covidien mallinckrodt pharmaceuticals' -> 'covidien mallinckrodt pharmaceutical generics' (similarity: 0.902)\n",
      "    Merging 'mallinckrodt' -> 'malinckrodt' (similarity: 0.957)\n",
      "    Merging 'covidien mallinckrodt pharmaceuticals' -> 'covidien mallinckrodt dosage pharmaceuticals' (similarity: 0.914)\n",
      "    Merging 'mckesson pharmaceuticals' -> 'mckesson pharmaceutical' (similarity: 0.979)\n",
      "    Merging 'walmart' -> 'wal mart' (similarity: 0.933)\n",
      "    Merging 'amerisourcebergen' -> 'amerisource bergen' (similarity: 0.971)\n",
      "    Merging 'par pharmaceuticals' -> 'par pharmaceutical' (similarity: 0.973)\n",
      "    Merging 'healthcare distribution management association hdma' -> 'healthcare distribution management association' (similarity: 0.948)\n",
      "    Merging 'national association of chain drug stores nacds' -> 'national association of chain drug stores' (similarity: 0.932)\n",
      "    Merging 'janssen pharmaceuticals' -> 'janssen pharmaceutica' (similarity: 0.955)\n",
      "    Merging 'qualitestrx' -> 'qualitest' (similarity: 0.900)\n",
      "    Merging 'hd smith' -> 'h d smith' (similarity: 0.941)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MAS_200/lib/python3.11/site-packages/neo4j/_sync/work/result.py:635: UserWarning: Expected a result with a single record, but found multiple.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Merging 'the american geriatrics society' -> 'american geriatrics society' (similarity: 0.931)\n",
      "    Merging 'teva pharmaceuticals' -> 'teva pharmaceutical' (similarity: 0.974)\n",
      "    Merging 'healthcare distribution alliance hda' -> 'healthcare distribution alliance' (similarity: 0.941)\n",
      "    Merging 'norwalk2' -> 'norwalk' (similarity: 0.933)\n",
      "    Merging 'national association of boards of pharmacy nabp' -> 'national association of boards of pharmacy' (similarity: 0.944)\n",
      "    Merging 'teva pharmaceuticals usa' -> 'teva pharmaceuticals' (similarity: 0.909)\n",
      "  âœ“ Successfully merged 23 organization node(s)\n",
      "  âš  Skipped 27 invalid merge(s)\n",
      "\n",
      "[4/4] Capturing AFTER statistics...\n",
      "\n",
      "======================================================================\n",
      "                       AFTER ENTITY RESOLUTION                        \n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š OVERALL:\n",
      "  Total Nodes:         16,987\n",
      "  Total Relationships: 30,105\n",
      "\n",
      "ðŸ“¦ NODES BY TYPE:\n",
      "  Person               4,036\n",
      "  TopicEntity          2,659\n",
      "  Email                2,217\n",
      "  Event                1,924\n",
      "  Concern              1,802\n",
      "  Decision             1,245\n",
      "  Location             818\n",
      "  Financial            612\n",
      "  Case                 605\n",
      "  Document             493\n",
      "  Organization         277\n",
      "  Place                224\n",
      "  RxNormDrug           75\n",
      "\n",
      "ðŸ”— RELATIONSHIPS BY TYPE:\n",
      "  EMAIL_MENTIONS_TOPIC      5,219\n",
      "  SENT_TO                   4,835\n",
      "  MENTIONS_PERSON_ENRICHED  3,709\n",
      "  HAS_EMAIL                 1,988\n",
      "  SENT                      1,969\n",
      "  HAS_EVENT                 1,924\n",
      "  HAS_CONCERN               1,802\n",
      "  EMAIL_MENTIONS_LOCATION   1,569\n",
      "  HAS_DECISION              1,245\n",
      "  REFERS_TO_EMAIL           1,243\n",
      "  AFFILIATED_WITH           950\n",
      "  HAS_ATTACHMENT            786\n",
      "  CASE_HAS_DOCUMENT         727\n",
      "  HAS_FINANCIAL             612\n",
      "  CASE_MENTIONS             475\n",
      "  EMAIL_MENTIONS_PLACE      473\n",
      "  FORWARDED_MESSAGE         325\n",
      "  EMAIL_MENTIONS_DRUG       229\n",
      "  SUBSIDIARY_OF             25\n",
      "\n",
      "ðŸ‘¥ PERSON DETAILS:\n",
      "  Total Persons:       4,036\n",
      "  With Email:          851\n",
      "  Without Email:       3,185\n",
      "\n",
      "ðŸ“§ OTHER:\n",
      "  Organizations:       277\n",
      "  Emails:              2,217\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "                  BEFORE vs AFTER ENTITY RESOLUTION                   \n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š OVERALL CHANGES:\n",
      "  Nodes:         17,614 â†’ 16,987 (+627 nodes, 3.6% reduction)\n",
      "  Relationships: 31,898 â†’ 30,105\n",
      "\n",
      "ðŸ“¦ NODE CHANGES BY TYPE:\n",
      "  Organization         289 â†’ 277 (-12)\n",
      "  Person               4,651 â†’ 4,036 (-615)\n",
      "\n",
      "ðŸ‘¥ PERSON CHANGES:\n",
      "  Total:       4,651 â†’ 4,036\n",
      "  Merged:      615 duplicate(s) removed\n",
      "  Reduction:   13.2% of persons were duplicates\n",
      "======================================================================\n",
      "\n",
      "â±ï¸  Entity Resolution completed in 13.08 seconds\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===============================================================================\n",
    "NEO4J KNOWLEDGE GRAPH IMPORT & ENTITY RESOLUTION PIPELINE\n",
    "===============================================================================\n",
    "\n",
    "PURPOSE:\n",
    "This script imports legal case data from JSONL files into a Neo4j graph database\n",
    "and resolves duplicate entities (people and organizations) to create a clean,\n",
    "connected knowledge graph.\n",
    "\n",
    "INPUT: \n",
    "- JSONL file where each line is a legal case with emails, people, organizations,\n",
    "  drugs, documents, and other entities\n",
    "\n",
    "OUTPUT:\n",
    "- Neo4j graph database with nodes (Person, Organization, Email, RxNormDrug, etc.)\n",
    "  and relationships (SENT, AFFILIATED_WITH, EMAIL_MENTIONS_DRUG, etc.)\n",
    "- Duplicate entities merged into single nodes\n",
    "- Statistics showing import success and entity resolution results\n",
    "\n",
    "WORKFLOW:\n",
    "1. Import all data from JSONL (creates duplicates)\n",
    "2. Preview duplicate entities\n",
    "3. Resolve duplicates by merging similar entities\n",
    "4. Report statistics\n",
    "\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import json, time, re, uuid\n",
    "from typing import Any, Dict, List, Union\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 1: UTILITY FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def ensure_list(x: Union[None, Dict[str, Any], List[Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert single items or None to lists for consistent processing.\n",
    "    \n",
    "    Args:\n",
    "        x: None, a dict, or a list of dicts\n",
    "        \n",
    "    Returns:\n",
    "        List of dicts (empty list if x is None)\n",
    "        \n",
    "    Example:\n",
    "        ensure_list(None) -> []\n",
    "        ensure_list({'name': 'John'}) -> [{'name': 'John'}]\n",
    "        ensure_list([{'name': 'John'}]) -> [{'name': 'John'}]\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    return [x]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 2: CASE-LEVEL IMPORT FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def upsert_case(tx, case_obj: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Create or update a Case node in Neo4j with all its connected entities.\n",
    "    \n",
    "    This is the top-level function that processes an entire legal case including:\n",
    "    - Case metadata (identifier, legal status, dates)\n",
    "    - Case-level entity mentions (topics, places)\n",
    "    - All emails within the case\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction object\n",
    "        case_obj: Dictionary containing case data from JSONL\n",
    "        \n",
    "    Process:\n",
    "        1. Create/update Case node with properties\n",
    "        2. Process case-level mentions (topics, places)\n",
    "        3. Recursively process all emails in the case\n",
    "    \"\"\"\n",
    "    case_id = case_obj.get(\"identifier\")\n",
    "    if not case_id:\n",
    "        return  # Skip if no case identifier\n",
    "\n",
    "    # STEP 1: Create or update the Case node\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (c:Case {identifier: $identifier})\n",
    "        SET\n",
    "          c.semantic_type = $semantic_type,\n",
    "          c.legalStatus = $legalStatus,\n",
    "          c.dateFiled = $dateFiled,\n",
    "          c.confidentialityNotice = $confidentialityNotice,\n",
    "          c.language = $language\n",
    "        \"\"\",\n",
    "        identifier=case_id,\n",
    "        semantic_type=case_obj.get(\"semantic_type\"),\n",
    "        legalStatus=case_obj.get(\"legalStatus\"),\n",
    "        dateFiled=case_obj.get(\"dateFiled\"),\n",
    "        confidentialityNotice=case_obj.get(\"confidentialityNotice\"),\n",
    "        language=case_obj.get(\"language\"),\n",
    "    )\n",
    "\n",
    "    # STEP 2: Process case-level mentions (entities mentioned in case description)\n",
    "    for mention in case_obj.get(\"mentions\") or []:\n",
    "        if isinstance(mention, dict):\n",
    "            upsert_case_mention(tx, case_id, mention)\n",
    "\n",
    "    # STEP 3: Process all emails that are part of this case\n",
    "    for email_obj in ensure_list(case_obj.get(\"hasPart\")):\n",
    "        if isinstance(email_obj, dict):\n",
    "            upsert_email_recursive(tx, case_id, email_obj, parent_email_id=None)\n",
    "\n",
    "\n",
    "def upsert_case_mention(tx, case_id: str, mention: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Create entity nodes for things mentioned in the case description.\n",
    "    \n",
    "    Creates two types of entities:\n",
    "    - Place nodes (for geographic locations like \"California\", \"New York\")\n",
    "    - TopicEntity nodes (for topics like \"drug safety\", \"clinical trials\")\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        case_id: Identifier of the parent case\n",
    "        mention: Dictionary with entity information\n",
    "        \n",
    "    Creates:\n",
    "        - Node: Place or TopicEntity\n",
    "        - Relationship: (Case)-[:CASE_MENTIONS]->(Entity)\n",
    "    \"\"\"\n",
    "    m_type = mention.get(\"@type\")\n",
    "    name = mention.get(\"name\")\n",
    "    if not name:\n",
    "        return  # Skip if no name\n",
    "\n",
    "    sem = mention.get(\"semantic_type\")\n",
    "    identifier = mention.get(\"identifier\")\n",
    "\n",
    "    # Determine node type based on entity type\n",
    "    if m_type == \"gpe\":  # GPE = Geopolitical Entity (cities, states, countries)\n",
    "        label = \"Place\"\n",
    "    else:\n",
    "        label = \"TopicEntity\"  # General topics, concepts, subjects\n",
    "\n",
    "    # STEP 1: Create or update the entity node\n",
    "    tx.run(\n",
    "        f\"\"\"\n",
    "        MERGE (m:{label} {{name: $name}})\n",
    "        SET\n",
    "          m.semantic_type = $semantic_type,\n",
    "          m.identifier = $identifier\n",
    "        \"\"\",\n",
    "        name=name,\n",
    "        semantic_type=sem,\n",
    "        identifier=identifier,\n",
    "    )\n",
    "\n",
    "    # STEP 2: Create relationship from Case to this entity\n",
    "    tx.run(\n",
    "        f\"\"\"\n",
    "        MATCH (c:Case {{identifier: $case_id}})\n",
    "        MATCH (m:{label} {{name: $name}})\n",
    "        MERGE (c)-[:CASE_MENTIONS]->(m)\n",
    "        \"\"\",\n",
    "        case_id=case_id,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 3: PERSON & ORGANIZATION IMPORT FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def upsert_person(tx, person: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Create or update a Person node in Neo4j.\n",
    "    \n",
    "    KEY CONCEPT: Each person needs a unique identifier (\"key\") to avoid duplicates.\n",
    "    The key is determined by:\n",
    "    1. Email address (if available) - most reliable\n",
    "    2. Name (if no email) - less reliable but better than nothing\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        person: Dictionary with person data (name, email, affiliation)\n",
    "        \n",
    "    Returns:\n",
    "        The unique key for this person (used to create relationships later)\n",
    "        \n",
    "    Creates:\n",
    "        - Node: Person with properties (name, email, key)\n",
    "        - Relationship: (Person)-[:AFFILIATED_WITH]->(Organization) if affiliation exists\n",
    "    \"\"\"\n",
    "    if not person:\n",
    "        return None\n",
    "\n",
    "    # Extract person data\n",
    "    name = person.get(\"name\") or \"Unknown\"\n",
    "    email_addr = person.get(\"email\")\n",
    "    sem = person.get(\"semantic_type\")\n",
    "    \n",
    "    # CRITICAL: Determine unique key for this person\n",
    "    # Priority: email > name (email is more unique)\n",
    "    key = email_addr or name\n",
    "\n",
    "    # STEP 1: Create or update Person node\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (p:Person {key: $key})\n",
    "        SET\n",
    "          p.name = $name,\n",
    "          p.email = $email,\n",
    "          p.semantic_type = $semantic_type\n",
    "        \"\"\",\n",
    "        key=key,\n",
    "        name=name,\n",
    "        email=email_addr,\n",
    "        semantic_type=sem,\n",
    "    )\n",
    "\n",
    "    # STEP 2: If person has organizational affiliation, create that too\n",
    "    aff = person.get(\"affiliation\")\n",
    "    if isinstance(aff, dict):\n",
    "        upsert_org_for_person(tx, key, aff)\n",
    "\n",
    "    return key  # Return key so caller can create relationships to this person\n",
    "\n",
    "\n",
    "def upsert_org_for_person(tx, person_key: str, org: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Create Organization nodes and link them to a Person.\n",
    "    \n",
    "    Handles organizational hierarchy:\n",
    "    - Creates the organization node\n",
    "    - Links person to organization\n",
    "    - If organization has a parent, creates that too\n",
    "    - Links child organization to parent\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        person_key: Unique key of the person\n",
    "        org: Dictionary with organization data\n",
    "        \n",
    "    Creates:\n",
    "        - Node: Organization\n",
    "        - Node: Parent Organization (if exists)\n",
    "        - Relationship: (Person)-[:AFFILIATED_WITH]->(Organization)\n",
    "        - Relationship: (Organization)-[:SUBSIDIARY_OF]->(Parent)\n",
    "        \n",
    "    Example:\n",
    "        Person \"John Smith\" works at \"Pfizer Research\"\n",
    "        \"Pfizer Research\" is subsidiary of \"Pfizer Inc\"\n",
    "        Creates: (John)-[:AFFILIATED_WITH]->(Pfizer Research)-[:SUBSIDIARY_OF]->(Pfizer Inc)\n",
    "    \"\"\"\n",
    "    name = org.get(\"name\")\n",
    "    if not name:\n",
    "        return\n",
    "\n",
    "    role = org.get(\"role\")  # e.g., \"researcher\", \"executive\"\n",
    "    sem = org.get(\"semantic_type\")\n",
    "\n",
    "    # STEP 1: Create or update Organization node\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (o:Organization {name: $name})\n",
    "        SET\n",
    "          o.semantic_type = $semantic_type,\n",
    "          o.role = $role\n",
    "        \"\"\",\n",
    "        name=name,\n",
    "        semantic_type=sem,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "    # STEP 2: Link Person to Organization\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MATCH (p:Person {key: $person_key})\n",
    "        MATCH (o:Organization {name: $name})\n",
    "        MERGE (p)-[:AFFILIATED_WITH]->(o)\n",
    "        \"\"\",\n",
    "        person_key=person_key,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "    # STEP 3: Handle parent organization (if exists)\n",
    "    parent = org.get(\"parentOrganization\")\n",
    "    if isinstance(parent, dict) and parent.get(\"name\"):\n",
    "        pname = parent.get(\"name\")\n",
    "        psem = parent.get(\"semantic_type\")\n",
    "        prole = parent.get(\"role\")\n",
    "\n",
    "        # Create parent organization node\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MERGE (po:Organization {name: $pname})\n",
    "            SET\n",
    "              po.semantic_type = $p_sem,\n",
    "              po.role = $p_role\n",
    "            \"\"\",\n",
    "            pname=pname,\n",
    "            p_sem=psem,\n",
    "            p_role=prole,\n",
    "        )\n",
    "\n",
    "        # Link child to parent organization\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (o:Organization {name: $name})\n",
    "            MATCH (po:Organization {name: $pname})\n",
    "            MERGE (o)-[:SUBSIDIARY_OF]->(po)\n",
    "            \"\"\",\n",
    "            name=name,\n",
    "            pname=pname,\n",
    "        )\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 4: EMAIL & DOCUMENT IMPORT FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def upsert_email_recursive(tx, case_id: str, email_obj: Dict[str, Any], parent_email_id: str = None):\n",
    "    \"\"\"\n",
    "    Create Email nodes and all connected entities recursively.\n",
    "    \n",
    "    This is a RECURSIVE function because emails can contain forwarded emails,\n",
    "    which can contain more forwarded emails, etc.\n",
    "    \n",
    "    Handles:\n",
    "    - Email metadata (subject, date, importance, body)\n",
    "    - Sender and recipients (creates Person nodes)\n",
    "    - Entity mentions in email (drugs, topics, locations)\n",
    "    - Documents attached to email\n",
    "    - Forwarded/nested emails (recursive)\n",
    "    - Email cross-references\n",
    "    - RxNorm drug mentions\n",
    "    - Enriched content (decisions, concerns, events, financials)\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        case_id: Parent case identifier\n",
    "        email_obj: Email data dictionary\n",
    "        parent_email_id: If this is a forwarded email, ID of parent email\n",
    "        \n",
    "    Creates:\n",
    "        - Node: Email\n",
    "        - Nodes: Person (sender, recipients)\n",
    "        - Nodes: RxNormDrug, TopicEntity, Location, Document, etc.\n",
    "        - Many relationships connecting all these entities\n",
    "    \"\"\"\n",
    "    if not email_obj:\n",
    "        return\n",
    "\n",
    "    # STEP 1: Get or generate email identifier\n",
    "    email_id = email_obj.get(\"identifier\") or email_obj.get(\"id\")\n",
    "    if not email_id:\n",
    "        # Generate ID from subject and date if not provided\n",
    "        email_id = f\"{email_obj.get('subject', 'Unknown')}|{email_obj.get('dateSent', '')}\"\n",
    "\n",
    "    # STEP 2: Create or update Email node\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (e:Email {identifier: $identifier})\n",
    "        SET\n",
    "          e.semantic_type = $semantic_type,\n",
    "          e.subject       = $subject,\n",
    "          e.dateSent      = $dateSent,\n",
    "          e.importance    = $importance,\n",
    "          e.body          = $body\n",
    "        \"\"\".strip(),\n",
    "        identifier=email_id,\n",
    "        semantic_type=email_obj.get(\"semantic_type\"),\n",
    "        subject=email_obj.get(\"subject\"),\n",
    "        dateSent=email_obj.get(\"dateSent\"),\n",
    "        importance=email_obj.get(\"importance\"),\n",
    "        body=email_obj.get(\"body\"),\n",
    "    )\n",
    "\n",
    "    # STEP 3: Link Email to its Case\n",
    "    if case_id:\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (c:Case {identifier: $case_id})\n",
    "            MATCH (e:Email {identifier: $email_id})\n",
    "            MERGE (c)-[:HAS_EMAIL]->(e)\n",
    "            \"\"\".strip(),\n",
    "            case_id=case_id,\n",
    "            email_id=email_id,\n",
    "        )\n",
    "\n",
    "    # STEP 4: Handle email threading (forwarded messages)\n",
    "    if parent_email_id:\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (parent:Email {identifier: $parent_id})\n",
    "            MATCH (child:Email {identifier: $email_id})\n",
    "            MERGE (parent)-[:FORWARDED_MESSAGE]->(child)\n",
    "            \"\"\".strip(),\n",
    "            parent_id=parent_email_id,\n",
    "            email_id=email_id,\n",
    "        )\n",
    "\n",
    "    # STEP 5: Process sender\n",
    "    sender = email_obj.get(\"sender\")\n",
    "    if isinstance(sender, dict):\n",
    "        sender_key = upsert_person(tx, sender)  # Create Person node\n",
    "        if sender_key:\n",
    "            # Link Person to Email with SENT relationship\n",
    "            tx.run(\n",
    "                \"\"\"\n",
    "                MATCH (e:Email {identifier: $email_id})\n",
    "                MATCH (p:Person {key: $sender_key})\n",
    "                MERGE (p)-[:SENT]->(e)\n",
    "                \"\"\".strip(),\n",
    "                email_id=email_id,\n",
    "                sender_key=sender_key,\n",
    "            )\n",
    "\n",
    "    # STEP 6: Process recipients (can be multiple)\n",
    "    for rcpt in email_obj.get(\"recipient\") or []:\n",
    "        if isinstance(rcpt, dict):\n",
    "            rcpt_key = upsert_person(tx, rcpt)  # Create Person node\n",
    "            if rcpt_key:\n",
    "                # Link Email to Person with SENT_TO relationship\n",
    "                tx.run(\n",
    "                    \"\"\"\n",
    "                    MATCH (e:Email {identifier: $email_id})\n",
    "                    MATCH (p:Person {key: $rcpt_key})\n",
    "                    MERGE (e)-[:SENT_TO]->(p)\n",
    "                    \"\"\".strip(),\n",
    "                    email_id=email_id,\n",
    "                    rcpt_key=rcpt_key,\n",
    "                )\n",
    "\n",
    "    # STEP 7: Process entity mentions (topics, places mentioned in email)\n",
    "    for mention in email_obj.get(\"mentions\") or []:\n",
    "        if isinstance(mention, dict):\n",
    "            upsert_mention_for_email(tx, email_id, mention)\n",
    "\n",
    "    # STEP 8: Process attachments (documents)\n",
    "    for att in email_obj.get(\"attachments\") or []:\n",
    "        if isinstance(att, dict):\n",
    "            upsert_attachment(tx, email_id, case_id, att)\n",
    "\n",
    "    # STEP 9: Process RxNorm drugs mentioned in email\n",
    "    for drug in email_obj.get(\"drugsRXnorm\") or []:\n",
    "        upsert_rxnorm_drug_for_email(tx, email_id, drug)\n",
    "\n",
    "    # STEP 10: Process enriched content (AI-extracted information)\n",
    "    enriched = email_obj.get(\"enriched_content\") or {}\n",
    "    if enriched:\n",
    "        upsert_enriched_content_for_email(tx, email_id, enriched)\n",
    "\n",
    "    # STEP 11: RECURSIVELY process forwarded/nested emails\n",
    "    fwd = email_obj.get(\"forwardedMessage\")\n",
    "    if isinstance(fwd, dict):\n",
    "        # Single forwarded email\n",
    "        upsert_email_recursive(tx, case_id, fwd, parent_email_id=email_id)\n",
    "    elif isinstance(fwd, list):\n",
    "        # Multiple forwarded emails\n",
    "        for child in fwd:\n",
    "            if isinstance(child, dict):\n",
    "                upsert_email_recursive(tx, case_id, child, parent_email_id=email_id)\n",
    "\n",
    "    # STEP 12: Process email cross-references (emails that mention other emails)\n",
    "    for me in email_obj.get(\"mentionsEmail\") or []:\n",
    "        if isinstance(me, dict):\n",
    "            ref_id = me.get(\"identifier\")\n",
    "            if ref_id:\n",
    "                upsert_cross_reference_email(\n",
    "                    tx,\n",
    "                    source_email_id=email_id,\n",
    "                    target_email_id=ref_id,\n",
    "                    similarity_score=None,\n",
    "                )\n",
    "\n",
    "    # STEP 13: Process cross-reference info (similar emails with scores)\n",
    "    cross = email_obj.get(\"crossRefInfo\") or {}\n",
    "    for cref in cross.get(\"crossRefEmails\") or []:\n",
    "        if isinstance(cref, dict):\n",
    "            cid = cref.get(\"cid\")  # Email ID\n",
    "            score = cref.get(\"score\")  # Similarity score\n",
    "            if cid:\n",
    "                upsert_cross_reference_email(\n",
    "                    tx,\n",
    "                    source_email_id=email_id,\n",
    "                    target_email_id=cid,\n",
    "                    similarity_score=score,\n",
    "                )\n",
    "\n",
    "\n",
    "def upsert_mention_for_email(tx, email_id: str, mention: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Create entity nodes for things mentioned IN an email.\n",
    "    \n",
    "    Similar to upsert_case_mention but for email-level entities.\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        email_id: Email that contains this mention\n",
    "        mention: Entity data\n",
    "        \n",
    "    Creates:\n",
    "        - Node: Place or TopicEntity\n",
    "        - Relationship: (Email)-[:EMAIL_MENTIONS_PLACE or EMAIL_MENTIONS_TOPIC]->(Entity)\n",
    "    \"\"\"\n",
    "    m_type = mention.get(\"@type\")\n",
    "    name = mention.get(\"name\")\n",
    "    if not name:\n",
    "        return\n",
    "\n",
    "    sem = mention.get(\"semantic_type\")\n",
    "    identifier = mention.get(\"identifier\")\n",
    "    role = mention.get(\"role\")\n",
    "\n",
    "    # Determine node type and relationship type\n",
    "    if m_type == \"gpe\":\n",
    "        label = \"Place\"\n",
    "        rel_type = \"EMAIL_MENTIONS_PLACE\"\n",
    "    else:\n",
    "        label = \"TopicEntity\"\n",
    "        rel_type = \"EMAIL_MENTIONS_TOPIC\"\n",
    "\n",
    "    # Create entity node\n",
    "    tx.run(\n",
    "        f\"\"\"\n",
    "        MERGE (m:{label} {{name: $name}})\n",
    "        SET\n",
    "          m.semantic_type = $semantic_type,\n",
    "          m.identifier = $identifier,\n",
    "          m.role = $role\n",
    "        \"\"\",\n",
    "        name=name,\n",
    "        semantic_type=sem,\n",
    "        identifier=identifier,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "    # Create relationship from email to entity\n",
    "    tx.run(\n",
    "        f\"\"\"\n",
    "        MATCH (e:Email {{identifier: $email_id}})\n",
    "        MATCH (m:{label} {{name: $name}})\n",
    "        MERGE (e)-[:{rel_type}]->(m)\n",
    "        \"\"\",\n",
    "        email_id=email_id,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "\n",
    "def upsert_attachment(tx, email_id: str, case_id: str, attachment: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Create Document nodes for email attachments.\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        email_id: Email that has this attachment\n",
    "        case_id: Parent case\n",
    "        attachment: Document data\n",
    "        \n",
    "    Creates:\n",
    "        - Node: Document\n",
    "        - Relationship: (Email)-[:HAS_ATTACHMENT]->(Document)\n",
    "        - Relationship: (Case)-[:CASE_HAS_DOCUMENT]->(Document)\n",
    "    \"\"\"\n",
    "    name = attachment.get(\"name\")\n",
    "    if not name:\n",
    "        return\n",
    "\n",
    "    sem = attachment.get(\"semantic_type\")\n",
    "    file_format = attachment.get(\"fileFormat\")  # PDF, DOCX, XLSX, etc.\n",
    "    desc = attachment.get(\"description\")\n",
    "\n",
    "    # Create Document node\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (d:Document {name: $name})\n",
    "        SET\n",
    "          d.semantic_type = $semantic_type,\n",
    "          d.fileFormat = $fileFormat,\n",
    "          d.description = $description\n",
    "        \"\"\",\n",
    "        name=name,\n",
    "        semantic_type=sem,\n",
    "        fileFormat=file_format,\n",
    "        description=desc,\n",
    "    )\n",
    "\n",
    "    # Link Email to Document\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MATCH (e:Email {identifier: $email_id})\n",
    "        MATCH (d:Document {name: $name})\n",
    "        MERGE (e)-[:HAS_ATTACHMENT]->(d)\n",
    "        \"\"\",\n",
    "        email_id=email_id,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "    # Link Case to Document\n",
    "    if case_id:\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (c:Case {identifier: $case_id})\n",
    "            MATCH (d:Document {name: $name})\n",
    "            MERGE (c)-[:CASE_HAS_DOCUMENT]->(d)\n",
    "            \"\"\",\n",
    "            case_id=case_id,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 5: SPECIALIZED ENTITY IMPORT FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def upsert_rxnorm_drug_for_email(tx, email_id: str, drug):\n",
    "    \"\"\"\n",
    "    Create RxNormDrug nodes for pharmaceutical drugs mentioned in emails.\n",
    "    \n",
    "    RxNorm is a standardized drug naming system. This function handles\n",
    "    drug data that can come in different formats (string or dict).\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        email_id: Email mentioning this drug\n",
    "        drug: Can be a string (\"Oxycodone\") or dict with details\n",
    "        \n",
    "    Creates:\n",
    "        - Node: RxNormDrug\n",
    "        - Relationship: (Email)-[:EMAIL_MENTIONS_DRUG]->(RxNormDrug)\n",
    "        \n",
    "    Example:\n",
    "        Input: \"Oxycodone\"\n",
    "        Creates: (RxNormDrug {name: \"Oxycodone\"})\n",
    "    \"\"\"\n",
    "    if drug is None:\n",
    "        return\n",
    "\n",
    "    # Handle different input formats\n",
    "    if isinstance(drug, str):\n",
    "        name = drug.strip()\n",
    "        rxcui = None  # RxNorm Concept Unique Identifier\n",
    "        source = None\n",
    "    elif isinstance(drug, dict):\n",
    "        name = (drug.get(\"name\") or drug.get(\"drug_name\") or drug.get(\"id\") or \"\").strip()\n",
    "        rxcui = drug.get(\"rxcui\") or drug.get(\"rxnorm_id\")\n",
    "        source = drug.get(\"source\") or drug.get(\"origin\") or \"RxNorm\"\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    if not name:\n",
    "        return\n",
    "\n",
    "    # Create drug node\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (d:RxNormDrug {name: $name})\n",
    "        SET\n",
    "          d.rxnorm_id = coalesce(d.rxnorm_id, $rxcui),\n",
    "          d.source    = coalesce(d.source, $source)\n",
    "        \"\"\".strip(),\n",
    "        name=name,\n",
    "        rxcui=rxcui,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    # Link Email to Drug\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MATCH (e:Email {identifier: $email_id})\n",
    "        MATCH (d:RxNormDrug {name: $name})\n",
    "        MERGE (e)-[:EMAIL_MENTIONS_DRUG]->(d)\n",
    "        \"\"\".strip(),\n",
    "        email_id=email_id,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "\n",
    "def upsert_enriched_content_for_email(tx, email_id: str, enriched):\n",
    "    \"\"\"\n",
    "    Create nodes for AI-extracted/enriched content from emails.\n",
    "    \n",
    "    This processes additional information extracted by AI/NLP from emails:\n",
    "    - Decisions made\n",
    "    - Concerns raised\n",
    "    - Events mentioned\n",
    "    - Financial information\n",
    "    - Locations mentioned\n",
    "    - People mentioned (beyond sender/recipient)\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        email_id: Email containing this enriched content\n",
    "        enriched: Dictionary with enriched data\n",
    "        \n",
    "    Creates multiple node types:\n",
    "        - Decision nodes: Important decisions mentioned\n",
    "        - Concern nodes: Issues/concerns raised\n",
    "        - Event nodes: Events referenced\n",
    "        - Financial nodes: Financial mentions\n",
    "        - Location nodes: Geographic locations\n",
    "        - Additional Person nodes: People mentioned in body\n",
    "    \"\"\"\n",
    "    if not enriched:\n",
    "        return\n",
    "\n",
    "    def _create_text_nodes(label: str, rel_type: str, items):\n",
    "        \"\"\"\n",
    "        Helper function to create nodes for text-based enriched content.\n",
    "        \n",
    "        Args:\n",
    "            label: Node label (Decision, Concern, Event, Financial)\n",
    "            rel_type: Relationship type\n",
    "            items: List of items to process\n",
    "        \"\"\"\n",
    "        for item in items or []:\n",
    "            if item is None:\n",
    "                continue\n",
    "            if isinstance(item, dict):\n",
    "                text = (item.get(\"text\") or item.get(\"value\") or \"\").strip()\n",
    "                source = item.get(\"source\")\n",
    "            else:\n",
    "                text = str(item).strip()\n",
    "                source = None\n",
    "            if not text:\n",
    "                continue\n",
    "            \n",
    "            # Create node and link to email\n",
    "            tx.run(\n",
    "                f\"\"\"\n",
    "                MATCH (e:Email {{identifier: $email_id}})\n",
    "                CREATE (n:{label} {{text: $text, source: $source}})\n",
    "                MERGE (e)-[:{rel_type}]->(n)\n",
    "                \"\"\".strip(),\n",
    "                email_id=email_id,\n",
    "                text=text,\n",
    "                source=source,\n",
    "            )\n",
    "\n",
    "    # Process different types of enriched content\n",
    "    _create_text_nodes(\"Decision\",  \"HAS_DECISION\",   enriched.get(\"decisions_made\"))\n",
    "    _create_text_nodes(\"Concern\",   \"HAS_CONCERN\",    enriched.get(\"concerns_raised\"))\n",
    "    _create_text_nodes(\"Event\",     \"HAS_EVENT\",      enriched.get(\"events_mentioned\"))\n",
    "    _create_text_nodes(\"Financial\", \"HAS_FINANCIAL\",  enriched.get(\"financial_mentions\"))\n",
    "\n",
    "    # Process locations\n",
    "    for loc in enriched.get(\"locations_mentioned\") or []:\n",
    "        if loc is None:\n",
    "            continue\n",
    "        if isinstance(loc, dict):\n",
    "            name = (loc.get(\"name\") or \"\").strip()\n",
    "            source = loc.get(\"source\")\n",
    "        else:\n",
    "            name = str(loc).strip()\n",
    "            source = None\n",
    "        if not name:\n",
    "            continue\n",
    "        \n",
    "        # Create Location node\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MERGE (l:Location {name: $name})\n",
    "            SET l.source = coalesce(l.source, $source)\n",
    "            \"\"\".strip(),\n",
    "            name=name,\n",
    "            source=source,\n",
    "        )\n",
    "        \n",
    "        # Link Email to Location\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (e:Email {identifier: $email_id})\n",
    "            MATCH (l:Location {name: $name})\n",
    "            MERGE (e)-[:EMAIL_MENTIONS_LOCATION]->(l)\n",
    "            \"\"\".strip(),\n",
    "            email_id=email_id,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "    # Process people mentioned (beyond sender/recipient)\n",
    "    for pm in enriched.get(\"people_mentioned\") or []:\n",
    "        if pm is None:\n",
    "            continue\n",
    "        if isinstance(pm, dict):\n",
    "            name = (pm.get(\"name\") or \"\").strip()\n",
    "            email_addr = pm.get(\"email\") or None\n",
    "        else:\n",
    "            name = str(pm).strip()\n",
    "            email_addr = None\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # Create Person node\n",
    "        person_dict = {\"name\": name, \"email\": email_addr, \"semantic_type\": \"Person\"}\n",
    "        person_key = upsert_person(tx, person_dict)\n",
    "        if person_key:\n",
    "            # Link Email to Person (different from SENT/SENT_TO)\n",
    "            tx.run(\n",
    "                \"\"\"\n",
    "                MATCH (p:Person {key: $key})\n",
    "                MATCH (e:Email {identifier: $email_id})\n",
    "                MERGE (e)-[:MENTIONS_PERSON_ENRICHED]->(p)\n",
    "                \"\"\".strip(),\n",
    "                key=person_key,\n",
    "                email_id=email_id,\n",
    "            )\n",
    "\n",
    "\n",
    "def upsert_cross_reference_email(tx, source_email_id: str, target_email_id: str, similarity_score: float = None):\n",
    "    \"\"\"\n",
    "    Create relationships between emails that reference each other.\n",
    "    \n",
    "    This handles email threading and cross-references with similarity scores.\n",
    "    \n",
    "    Args:\n",
    "        tx: Neo4j transaction\n",
    "        source_email_id: Email that references another\n",
    "        target_email_id: Email being referenced\n",
    "        similarity_score: Optional similarity score (0-1) between emails\n",
    "        \n",
    "    Creates:\n",
    "        - Nodes: Both emails (if they don't exist)\n",
    "        - Relationship: (Email)-[:REFERS_TO_EMAIL {similarity_score}]->(Email)\n",
    "        \n",
    "    Example:\n",
    "        Email A says \"As discussed in email B...\"\n",
    "        Creates: (Email A)-[:REFERS_TO_EMAIL]->(Email B)\n",
    "    \"\"\"\n",
    "    if not source_email_id or not target_email_id:\n",
    "        return\n",
    "\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (src:Email {identifier: $source_id})\n",
    "        MERGE (tgt:Email {identifier: $target_id})\n",
    "        MERGE (src)-[r:REFERS_TO_EMAIL]->(tgt)\n",
    "        SET r.similarity_score = $similarity_score\n",
    "        \"\"\".strip(),\n",
    "        source_id=source_email_id,\n",
    "        target_id=target_email_id,\n",
    "        similarity_score=similarity_score,\n",
    "    )\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 6: MAIN IMPORT FUNCTION\n",
    "# =====================================================================\n",
    "\n",
    "def import_jsonl_to_neo4j(\n",
    "    jsonl_path: str,\n",
    "    uri: str,\n",
    "    user: str,\n",
    "    password: str,\n",
    "    log_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main import function: Read JSONL file and import all data to Neo4j.\n",
    "    \n",
    "    JSONL Format: Each line is a JSON object representing one legal case\n",
    "    with nested emails, people, organizations, etc.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to JSONL file\n",
    "        uri: Neo4j connection URI (e.g., \"neo4j://localhost:7687\")\n",
    "        user: Neo4j username\n",
    "        password: Neo4j password\n",
    "        log_every: Print progress every N lines\n",
    "        \n",
    "    Process:\n",
    "        1. Connect to Neo4j\n",
    "        2. Read JSONL file line by line\n",
    "        3. Parse each line as a case\n",
    "        4. Import case and all nested entities\n",
    "        5. Handle errors gracefully (continue on failure)\n",
    "        6. Report statistics\n",
    "        \n",
    "    Features:\n",
    "        - Progress logging\n",
    "        - Error handling per line (one bad line doesn't kill whole import)\n",
    "        - Statistics tracking (success, failure, skipped)\n",
    "        - Performance timing\n",
    "    \"\"\"\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    # Statistics counters\n",
    "    total_lines = 0\n",
    "    success_cases = 0\n",
    "    skipped_lines = 0\n",
    "    failed_cases = 0\n",
    "\n",
    "    with driver.session() as session:\n",
    "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Process each line in JSONL file\n",
    "            for line_no, line in enumerate(f, start=1):\n",
    "                total_lines += 1\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Skip empty lines\n",
    "                if not line:\n",
    "                    skipped_lines += 1\n",
    "                    continue\n",
    "\n",
    "                # Progress logging\n",
    "                if line_no % log_every == 0:\n",
    "                    print(f\"[INFO] Processing line {line_no}... (success={success_cases}, failed={failed_cases}, skipped={skipped_lines})\")\n",
    "                    print('\\t took', time.time() - start_time, 'seconds')\n",
    "\n",
    "                # STEP 1: Parse the JSON wrapper\n",
    "                try:\n",
    "                    wrapper = json.loads(line)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"[WARN] Skipping line {line_no}: invalid JSON wrapper ({e})\")\n",
    "                    skipped_lines += 1\n",
    "                    continue\n",
    "\n",
    "                # STEP 2: Extract the 'output' field (contains actual case data)\n",
    "                output_raw = wrapper.get(\"output\")\n",
    "                if not output_raw:\n",
    "                    print(f\"[WARN] Skipping line {line_no}: no 'output' field\")\n",
    "                    skipped_lines += 1\n",
    "                    continue\n",
    "\n",
    "                # STEP 3: Parse the case object\n",
    "                try:\n",
    "                    case_obj = json.loads(output_raw)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Sometimes output is already a dict, not a string\n",
    "                    if isinstance(output_raw, dict):\n",
    "                        case_obj = output_raw\n",
    "                    else:\n",
    "                        print(f\"[WARN] Skipping line {line_no}: invalid 'output' JSON\")\n",
    "                        skipped_lines += 1\n",
    "                        continue\n",
    "\n",
    "                case_id = case_obj.get(\"identifier\")\n",
    "\n",
    "                # STEP 4: Import this case to Neo4j (with error handling)\n",
    "                try:\n",
    "                    def work(tx):\n",
    "                        upsert_case(tx, case_obj)\n",
    "\n",
    "                    session.execute_write(work)\n",
    "                    success_cases += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Don't let one bad case kill the whole import\n",
    "                    failed_cases += 1\n",
    "                    print(f\"[ERROR] Failed to import case on line {line_no} (case_id={case_id!r}): {type(e).__name__}: {e}\")\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    # Print final statistics\n",
    "    print(\"\\n=== Import summary ===\")\n",
    "    print(f\"Total lines read:     {total_lines}\")\n",
    "    print(f\"Successful cases:     {success_cases}\")\n",
    "    print(f\"Failed cases:         {failed_cases}\")\n",
    "    print(f\"Skipped lines:        {skipped_lines}\")\n",
    "    print('Runtime (s):          ', time.time() - start_time)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 7: ENTITY RESOLUTION - STATISTICS CLASS\n",
    "# =====================================================================\n",
    "\n",
    "class GraphStats:\n",
    "    \"\"\"\n",
    "    Helper class to collect and display graph statistics.\n",
    "    \n",
    "    Used to measure the impact of entity resolution by comparing\n",
    "    graph state before and after merging duplicates.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_stats(driver) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Collect comprehensive statistics about the graph.\n",
    "        \n",
    "        Queries Neo4j to count:\n",
    "        - Nodes by type (Person, Email, Organization, etc.)\n",
    "        - Relationships by type (SENT, AFFILIATED_WITH, etc.)\n",
    "        - Specific details about Persons and Organizations\n",
    "        \n",
    "        Args:\n",
    "            driver: Neo4j driver instance\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with all statistics\n",
    "        \"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        with driver.session() as session:\n",
    "            # Count nodes by type\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n)\n",
    "                RETURN labels(n)[0] as label, count(*) as count\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            node_counts = {record['label']: record['count'] for record in result}\n",
    "            stats['nodes'] = node_counts\n",
    "            stats['total_nodes'] = sum(node_counts.values())\n",
    "            \n",
    "            # Count relationships by type\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH ()-[r]->()\n",
    "                RETURN type(r) as rel_type, count(*) as count\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            rel_counts = {record['rel_type']: record['count'] for record in result}\n",
    "            stats['relationships'] = rel_counts\n",
    "            stats['total_relationships'] = sum(rel_counts.values())\n",
    "            \n",
    "            # Detailed person statistics\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (p:Person)\n",
    "                WITH count(p) as total,\n",
    "                     sum(CASE WHEN p.email IS NOT NULL THEN 1 ELSE 0 END) as with_email,\n",
    "                     sum(CASE WHEN p.email IS NULL THEN 1 ELSE 0 END) as without_email\n",
    "                RETURN total, with_email, without_email\n",
    "            \"\"\")\n",
    "            person_stats = result.single()\n",
    "            if person_stats:\n",
    "                stats['persons'] = {\n",
    "                    'total': person_stats['total'],\n",
    "                    'with_email': person_stats['with_email'],\n",
    "                    'without_email': person_stats['without_email']\n",
    "                }\n",
    "            \n",
    "            # Count organizations\n",
    "            result = session.run(\"MATCH (o:Organization) RETURN count(o) as count\")\n",
    "            stats['organizations'] = result.single()['count']\n",
    "            \n",
    "            # Count emails\n",
    "            result = session.run(\"MATCH (e:Email) RETURN count(e) as count\")\n",
    "            stats['emails'] = result.single()['count']\n",
    "            \n",
    "        return stats\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_stats(stats: Dict[str, Any], title: str = \"Graph Statistics\"):\n",
    "        \"\"\"Print statistics in a formatted, readable way.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"{title:^70}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š OVERALL:\")\n",
    "        print(f\"  Total Nodes:         {stats['total_nodes']:,}\")\n",
    "        print(f\"  Total Relationships: {stats['total_relationships']:,}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“¦ NODES BY TYPE:\")\n",
    "        for label, count in sorted(stats['nodes'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {label:20s} {count:,}\")\n",
    "        \n",
    "        print(f\"\\nðŸ”— RELATIONSHIPS BY TYPE:\")\n",
    "        for rel_type, count in sorted(stats['relationships'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {rel_type:25s} {count:,}\")\n",
    "        \n",
    "        if 'persons' in stats:\n",
    "            print(f\"\\nðŸ‘¥ PERSON DETAILS:\")\n",
    "            print(f\"  Total Persons:       {stats['persons']['total']:,}\")\n",
    "            print(f\"  With Email:          {stats['persons']['with_email']:,}\")\n",
    "            print(f\"  Without Email:       {stats['persons']['without_email']:,}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“§ OTHER:\")\n",
    "        print(f\"  Organizations:       {stats.get('organizations', 0):,}\")\n",
    "        print(f\"  Emails:              {stats.get('emails', 0):,}\")\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_comparison(before: Dict[str, Any], after: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Print before/after comparison showing impact of entity resolution.\n",
    "        \n",
    "        Shows how many nodes were merged and percentage reduction.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"{'BEFORE vs AFTER ENTITY RESOLUTION':^70}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        node_reduction = before['total_nodes'] - after['total_nodes']\n",
    "        node_reduction_pct = (node_reduction / before['total_nodes'] * 100) if before['total_nodes'] > 0 else 0\n",
    "        \n",
    "        print(f\"\\nðŸ“Š OVERALL CHANGES:\")\n",
    "        print(f\"  Nodes:         {before['total_nodes']:,} â†’ {after['total_nodes']:,} ({node_reduction:+,} nodes, {node_reduction_pct:.1f}% reduction)\")\n",
    "        print(f\"  Relationships: {before['total_relationships']:,} â†’ {after['total_relationships']:,}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“¦ NODE CHANGES BY TYPE:\")\n",
    "        all_labels = set(before['nodes'].keys()) | set(after['nodes'].keys())\n",
    "        for label in sorted(all_labels):\n",
    "            before_count = before['nodes'].get(label, 0)\n",
    "            after_count = after['nodes'].get(label, 0)\n",
    "            change = after_count - before_count\n",
    "            if change != 0:\n",
    "                print(f\"  {label:20s} {before_count:,} â†’ {after_count:,} ({change:+,})\")\n",
    "        \n",
    "        if 'persons' in before and 'persons' in after:\n",
    "            print(f\"\\nðŸ‘¥ PERSON CHANGES:\")\n",
    "            before_persons = before['persons']['total']\n",
    "            after_persons = after['persons']['total']\n",
    "            merged = before_persons - after_persons\n",
    "            print(f\"  Total:       {before_persons:,} â†’ {after_persons:,}\")\n",
    "            print(f\"  Merged:      {merged:,} duplicate(s) removed\")\n",
    "            if merged > 0:\n",
    "                print(f\"  Reduction:   {merged/before_persons*100:.1f}% of persons were duplicates\")\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SECTION 8: ENTITY RESOLUTION - RESOLVER CLASS\n",
    "# =====================================================================\n",
    "\n",
    "class EntityResolver:\n",
    "    \"\"\"\n",
    "    Main class for entity resolution (merging duplicate nodes).\n",
    "    \n",
    "    PROBLEM: During import, the same person or organization might be created\n",
    "    multiple times with slight variations in names:\n",
    "    - \"John Smith\" vs \"J. Smith\" vs \"Smith, John\"\n",
    "    - \"Microsoft Corp\" vs \"Microsoft Corporation\" vs \"Microsoft\"\n",
    "    \n",
    "    SOLUTION: This class finds and merges similar entities based on:\n",
    "    - String similarity matching\n",
    "    - Email address matching (for persons)\n",
    "    - Normalized name comparison\n",
    "    \n",
    "    APPROACH:\n",
    "    1. Find duplicates using similarity thresholds\n",
    "    2. Preview what would be merged (optional)\n",
    "    3. Merge duplicate nodes by transferring relationships\n",
    "    4. Track statistics before/after\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, uri: str, user: str, password: str):\n",
    "        \"\"\"Initialize connection to Neo4j.\"\"\"\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self.stats_before = None\n",
    "        self.stats_after = None\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close Neo4j connection.\"\"\"\n",
    "        self.driver.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize_string(s: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalize string for comparison.\n",
    "        \n",
    "        Removes noise that prevents matching:\n",
    "        - Converts to lowercase\n",
    "        - Removes punctuation\n",
    "        - Removes extra spaces\n",
    "        - Removes common company suffixes (Inc, LLC, Corp, etc.)\n",
    "        \n",
    "        Example:\n",
    "            \"Microsoft Corporation\" -> \"microsoft\"\n",
    "            \"Smith, John Jr.\" -> \"smith john jr\"\n",
    "        \"\"\"\n",
    "        if not s:\n",
    "            return \"\"\n",
    "        s = s.lower().strip()\n",
    "        s = re.sub(r'[^\\w\\s]', ' ', s)  # Remove punctuation\n",
    "        s = re.sub(r'\\s+', ' ', s).strip()  # Collapse spaces\n",
    "        \n",
    "        # Remove common company suffixes\n",
    "        suffixes = [' inc', ' llc', ' lp', ' llp', ' corp', ' corporation', ' co', ' ltd', ' plc']\n",
    "        for suffix in suffixes:\n",
    "            if s.endswith(suffix):\n",
    "                s = s[:-len(suffix)].strip()\n",
    "        return s\n",
    "        \n",
    "    @staticmethod\n",
    "    def similarity_score(s1: str, s2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate similarity between two strings (0-1 scale).\n",
    "        \n",
    "        Uses SequenceMatcher algorithm which compares character sequences.\n",
    "        \n",
    "        Returns:\n",
    "            0.0 = completely different\n",
    "            1.0 = identical\n",
    "            0.9 = very similar (might be duplicate)\n",
    "            \n",
    "        Example:\n",
    "            similarity(\"John Smith\", \"J. Smith\") -> 0.72\n",
    "            similarity(\"Microsoft\", \"Microsoft Corp\") -> 0.85\n",
    "        \"\"\"\n",
    "        s1_norm = EntityResolver.normalize_string(s1)\n",
    "        s2_norm = EntityResolver.normalize_string(s2)\n",
    "        return SequenceMatcher(None, s1_norm, s2_norm).ratio()\n",
    "    \n",
    "    def find_duplicate_persons(self, threshold: float = 0.9) -> List[tuple]:\n",
    "        \"\"\"\n",
    "        Find potential duplicate person nodes using intelligent blocking.\n",
    "        \n",
    "        CHALLENGE: Comparing every person with every other person is O(nÂ²)\n",
    "        which is too slow for thousands of people.\n",
    "        \n",
    "        SOLUTION: Use \"blocking\" - group similar people together first,\n",
    "        then only compare within groups. Groups are based on:\n",
    "        - Email domain (people@company.com)\n",
    "        - First word of name (all \"John\" names compared together)\n",
    "        \n",
    "        Args:\n",
    "            threshold: Similarity score threshold (0-1) for considering duplicates\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples: (person1_key, person2_key, similarity_score)\n",
    "            \n",
    "        Algorithm:\n",
    "        1. Fetch all persons from database\n",
    "        2. Create blocks (groups) by email domain and name\n",
    "        3. Compare persons only within same block\n",
    "        4. Return pairs with similarity >= threshold\n",
    "        \"\"\"\n",
    "        duplicates = []\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Fetch all persons with their organizations\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (p:Person)\n",
    "                OPTIONAL MATCH (p)-[:AFFILIATED_WITH]->(o:Organization)\n",
    "                RETURN p.key as key, p.name as name, p.email as email, \n",
    "                       collect(DISTINCT o.name) as orgs\n",
    "            \"\"\")\n",
    "            \n",
    "            persons = list(result)\n",
    "            \n",
    "            # Create blocks for efficient comparison\n",
    "            email_blocks = defaultdict(list)\n",
    "            name_blocks = defaultdict(list)\n",
    "            \n",
    "            for p in persons:\n",
    "                # Skip invalid persons\n",
    "                if not p['key'] or p['key'] == 'None' or not isinstance(p['key'], str):\n",
    "                    continue\n",
    "                if p['key'].startswith('unknown:'):\n",
    "                    continue\n",
    "                    \n",
    "                # Block by email domain\n",
    "                if p.get('email') and '@' in p['email']:\n",
    "                    domain = p['email'].split('@')[-1].lower()\n",
    "                    if domain:\n",
    "                        email_blocks[domain].append(p)\n",
    "                \n",
    "                # Block by first word of name\n",
    "                if p.get('name') and p['name'].lower() not in ['unknown', '[unknown]']:\n",
    "                    normalized = self.normalize_string(p['name'])\n",
    "                    if normalized:\n",
    "                        first_word = normalized.split()[0] if normalized.split() else ''\n",
    "                        if first_word and len(first_word) > 2:\n",
    "                            name_blocks[first_word].append(p)\n",
    "            \n",
    "            # Compare within blocks only\n",
    "            seen = set()\n",
    "            \n",
    "            # Process email blocks (high confidence)\n",
    "            for block in email_blocks.values():\n",
    "                for i, p1 in enumerate(block):\n",
    "                    for p2 in block[i+1:]:\n",
    "                        pair = tuple(sorted([p1['key'], p2['key']]))\n",
    "                        if pair in seen:\n",
    "                            continue\n",
    "                        seen.add(pair)\n",
    "                        \n",
    "                        # Exact email match = definite duplicate\n",
    "                        if p1.get('email') and p2.get('email'):\n",
    "                            if p1['email'].lower() == p2['email'].lower():\n",
    "                                duplicates.append((p1['key'], p2['key'], 1.0))\n",
    "                                continue\n",
    "                        \n",
    "                        # Name similarity check\n",
    "                        if p1.get('name') and p2.get('name'):\n",
    "                            name_sim = self.similarity_score(p1['name'], p2['name'])\n",
    "                            if name_sim >= threshold:\n",
    "                                duplicates.append((p1['key'], p2['key'], name_sim))\n",
    "            \n",
    "            # Process name blocks (lower confidence, higher threshold)\n",
    "            for block in name_blocks.values():\n",
    "                for i, p1 in enumerate(block):\n",
    "                    for p2 in block[i+1:]:\n",
    "                        pair = tuple(sorted([p1['key'], p2['key']]))\n",
    "                        if pair in seen:\n",
    "                            continue\n",
    "                        seen.add(pair)\n",
    "                        \n",
    "                        # Stricter threshold for name-only matches\n",
    "                        name_sim = self.similarity_score(p1.get('name', ''), p2.get('name', ''))\n",
    "                        if name_sim >= min(threshold + 0.05, 0.98):\n",
    "                            duplicates.append((p1['key'], p2['key'], name_sim))\n",
    "        \n",
    "        return duplicates\n",
    "    \n",
    "    def merge_persons(self, keep_key: str, merge_key: str):\n",
    "        \"\"\"\n",
    "        Merge two person nodes into one.\n",
    "        \n",
    "        Process:\n",
    "        1. Validate keys (no empty, None, or self-merges)\n",
    "        2. Transfer all relationships from merge_key to keep_key\n",
    "        3. Merge properties (keep best available data)\n",
    "        4. Delete the merged node\n",
    "        \n",
    "        Args:\n",
    "            keep_key: Key of person to keep\n",
    "            merge_key: Key of person to merge (will be deleted)\n",
    "        \"\"\"\n",
    "        # Validation\n",
    "        if not keep_key or not merge_key:\n",
    "            print(f\"  âœ— Skipping invalid merge: empty key\")\n",
    "            return\n",
    "        if str(keep_key) == 'None' or str(merge_key) == 'None':\n",
    "            print(f\"  âœ— Skipping invalid merge: None key\")\n",
    "            return\n",
    "        if keep_key == merge_key:\n",
    "            print(f\"  âœ— Skipping self-merge: {keep_key}\")\n",
    "            return\n",
    "        if keep_key.startswith('unknown:') or merge_key.startswith('unknown:'):\n",
    "            print(f\"  âœ— Skipping auto-generated unknown key merge\")\n",
    "            return\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            session.execute_write(self._do_merge_persons, keep_key, merge_key)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _do_merge_persons(tx, keep_key: str, merge_key: str):\n",
    "        \"\"\"\n",
    "        Transaction function to perform the actual person merge.\n",
    "        \n",
    "        Transfers all relationships and properties from merge node to keep node.\n",
    "        \"\"\"\n",
    "        # Transfer SENT relationships (emails sent by this person)\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (merge:Person {key: $merge_key})-[r:SENT]->(e:Email)\n",
    "            MATCH (keep:Person {key: $keep_key})\n",
    "            MERGE (keep)-[:SENT]->(e)\n",
    "            DELETE r\n",
    "        \"\"\", keep_key=keep_key, merge_key=merge_key)\n",
    "        \n",
    "        # Transfer SENT_TO relationships (emails received by this person)\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (e:Email)-[r:SENT_TO]->(merge:Person {key: $merge_key})\n",
    "            MATCH (keep:Person {keep_key: $keep_key})\n",
    "            MERGE (e)-[:SENT_TO]->(keep)\n",
    "            DELETE r\n",
    "        \"\"\", keep_key=keep_key, merge_key=merge_key)\n",
    "        \n",
    "        # Transfer AFFILIATED_WITH relationships\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (merge:Person {key: $merge_key})-[r:AFFILIATED_WITH]->(o:Organization)\n",
    "            MATCH (keep:Person {key: $keep_key})\n",
    "            MERGE (keep)-[:AFFILIATED_WITH]->(o)\n",
    "            DELETE r\n",
    "        \"\"\", keep_key=keep_key, merge_key=merge_key)\n",
    "        \n",
    "        # Merge properties (keep best available)\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (merge:Person {key: $merge_key})\n",
    "            MATCH (keep:Person {key: $keep_key})\n",
    "            SET keep.email = COALESCE(keep.email, merge.email),\n",
    "                keep.name = CASE \n",
    "                    WHEN keep.name IN ['Unknown', '[unknown]', ''] THEN merge.name\n",
    "                    ELSE keep.name\n",
    "                END,\n",
    "                keep.semantic_type = COALESCE(keep.semantic_type, merge.semantic_type)\n",
    "        \"\"\", keep_key=keep_key, merge_key=merge_key)\n",
    "        \n",
    "        # Delete the merged node\n",
    "        tx.run(\"MATCH (p:Person {key: $merge_key}) DETACH DELETE p\", merge_key=merge_key)\n",
    "    \n",
    "    def find_duplicate_organizations(self, threshold: float = 0.85) -> List[tuple]:\n",
    "        \"\"\"\n",
    "        Find duplicate organization nodes by name similarity.\n",
    "        \n",
    "        Similar to find_duplicate_persons but simpler since organizations\n",
    "        only have names (no email addresses).\n",
    "        \n",
    "        Returns:\n",
    "            List of tuples: (org1_name, org2_name, similarity_score)\n",
    "        \"\"\"\n",
    "        duplicates = []\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"MATCH (o:Organization) RETURN o.name as name\")\n",
    "            orgs = list(result)\n",
    "\n",
    "            # Normalize all organization names\n",
    "            normalized_map = {}\n",
    "            for org in orgs:\n",
    "                if not org['name']:\n",
    "                    continue\n",
    "                normalized = self.normalize_string(org['name'])\n",
    "                if normalized:\n",
    "                    normalized_map[org['name']] = normalized\n",
    "\n",
    "            # Compare normalized names\n",
    "            seen = set()\n",
    "            names = list(normalized_map.keys())\n",
    "            for i, o1 in enumerate(names):\n",
    "                for o2 in names[i+1:]:\n",
    "                    n1 = normalized_map[o1]\n",
    "                    n2 = normalized_map[o2]\n",
    "                    pair = tuple(sorted([n1, n2]))\n",
    "                    if pair in seen:\n",
    "                        continue\n",
    "                    seen.add(pair)\n",
    "\n",
    "                    score = SequenceMatcher(None, n1, n2).ratio()\n",
    "                    if score >= threshold:\n",
    "                        # Always merge into alphabetically first\n",
    "                        keep = min(n1, n2)\n",
    "                        merge = max(n1, n2)\n",
    "                        duplicates.append((keep, merge, score))\n",
    "\n",
    "        return duplicates\n",
    "\n",
    "    def merge_organizations(self, keep_norm: str, merge_norm: str):\n",
    "        \"\"\"\n",
    "        Merge two organization nodes.\n",
    "        \n",
    "        Similar process to merge_persons but for organizations.\n",
    "        \"\"\"\n",
    "        # Convert normalized names back to actual node names\n",
    "        with self.driver.session() as session:\n",
    "            keep_node = session.run(\n",
    "                \"MATCH (o:Organization) WHERE toLower(o.name) CONTAINS $norm RETURN o.name as name\",\n",
    "                norm=keep_norm\n",
    "            ).single()\n",
    "            merge_node = session.run(\n",
    "                \"MATCH (o:Organization) WHERE toLower(o.name) CONTAINS $norm RETURN o.name as name\",\n",
    "                norm=merge_norm\n",
    "            ).single()\n",
    "\n",
    "        if keep_node and merge_node:\n",
    "            self._do_merge_orgs(self.driver.session(), keep_node['name'], merge_node['name'])\n",
    "\n",
    "    @staticmethod\n",
    "    def _do_merge_orgs(tx, keep_name: str, merge_name: str):\n",
    "        \"\"\"Transaction function to merge organization nodes.\"\"\"\n",
    "        # Transfer all relationship types that organizations have\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (p:Person)-[r:AFFILIATED_WITH]->(merge:Organization {name: $merge_name})\n",
    "            MATCH (keep:Organization {name: $keep_name})\n",
    "            MERGE (p)-[:AFFILIATED_WITH]->(keep)\n",
    "            DELETE r\n",
    "        \"\"\", keep_name=keep_name, merge_name=merge_name)\n",
    "        \n",
    "        tx.run(\"\"\"\n",
    "            MATCH (sub:Organization)-[r:SUBSIDIARY_OF]->(merge:Organization {name: $merge_name})\n",
    "            MATCH (keep:Organization {name: $keep_name})\n",
    "            MERGE (sub)-[:SUBSIDIARY_OF]->(keep)\n",
    "            DELETE r\n",
    "        \"\"\", keep_name=keep_name, merge_name=merge_name)\n",
    "        \n",
    "        tx.run(\"\"\"\n",
    "            MATCH (merge:Organization {name: $merge_name})\n",
    "            MATCH (keep:Organization {name: $keep_name})\n",
    "            OPTIONAL MATCH (merge)-[r:SUBSIDIARY_OF]->(parent:Organization)\n",
    "            WITH keep, parent, r\n",
    "            WHERE parent IS NOT NULL\n",
    "            MERGE (keep)-[:SUBSIDIARY_OF]->(parent)\n",
    "            DELETE r\n",
    "        \"\"\", keep_name=keep_name, merge_name=merge_name)\n",
    "        \n",
    "        tx.run(\"\"\"\n",
    "            MATCH (merge:Organization {name: $merge_name})\n",
    "            MATCH (keep:Organization {name: $keep_name})\n",
    "            SET keep.semantic_type = COALESCE(keep.semantic_type, merge.semantic_type),\n",
    "                keep.role = COALESCE(keep.role, merge.role)\n",
    "        \"\"\", keep_name=keep_name, merge_name=merge_name)\n",
    "        \n",
    "        tx.run(\"\"\"\n",
    "            MATCH (merge:Organization {name: $merge_name})\n",
    "            DETACH DELETE merge\n",
    "        \"\"\", merge_name=merge_name)\n",
    "    def preview_duplicates(self, person_threshold: float = 0.9, org_threshold: float = 0.85):\n",
    "        \"\"\"Preview what duplicates would be found without merging\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"{'DUPLICATE PREVIEW (No Merging)':^70}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Get current stats\n",
    "        stats = GraphStats.get_stats(self.driver)\n",
    "        GraphStats.print_stats(stats, \"CURRENT GRAPH STATE\")\n",
    "        \n",
    "        # Preview person duplicates\n",
    "        print(f\"\\nðŸ‘¥ POTENTIAL PERSON DUPLICATES (threshold={person_threshold}):\")\n",
    "        person_dupes = self.find_duplicate_persons(person_threshold)\n",
    "        \n",
    "        if not person_dupes:\n",
    "            print(\"  âœ“ No person duplicates found!\")\n",
    "        else:\n",
    "            print(f\"  Found {len(person_dupes)} potential duplicate pair(s):\\n\")\n",
    "            \n",
    "            # Fetch details for better display\n",
    "            with self.driver.session() as session:\n",
    "                shown = 0\n",
    "                for i, (key1, key2, score) in enumerate(person_dupes, 1):\n",
    "                    if shown >= 10:  # Only show first 10\n",
    "                        break\n",
    "                    \n",
    "                    # Check if both persons still exist\n",
    "                    p1 = session.run(\n",
    "                        \"MATCH (p:Person {key: $key}) RETURN p.name as name, p.email as email\",\n",
    "                        key=key1\n",
    "                    ).single()\n",
    "                    p2 = session.run(\n",
    "                        \"MATCH (p:Person {key: $key}) RETURN p.name as name, p.email as email\",\n",
    "                        key=key2\n",
    "                    ).single()\n",
    "                    \n",
    "                    # Skip if either person was already deleted\n",
    "                    if not p1 or not p2:\n",
    "                        continue\n",
    "                    \n",
    "                    shown += 1\n",
    "                    print(f\"  [{shown}] Similarity: {score:.3f}\")\n",
    "                    print(f\"      Person A: {p1['name']} ({p1['email'] or 'no email'})\")\n",
    "                    print(f\"      Person B: {p2['name']} ({p2['email'] or 'no email'})\")\n",
    "                    print()\n",
    "            \n",
    "            if len(person_dupes) > 10:\n",
    "                print(f\"  ... and {len(person_dupes) - 10} more duplicate pair(s)\")\n",
    "        \n",
    "        # Preview organization duplicates\n",
    "        print(f\"\\nðŸ¢ POTENTIAL ORGANIZATION DUPLICATES (threshold={org_threshold}):\")\n",
    "        org_dupes = self.find_duplicate_organizations(org_threshold)\n",
    "        \n",
    "        if not org_dupes:\n",
    "            print(\"  âœ“ No organization duplicates found!\")\n",
    "        else:\n",
    "            print(f\"  Found {len(org_dupes)} potential duplicate pair(s):\\n\")\n",
    "            \n",
    "            with self.driver.session() as session:\n",
    "                shown = 0\n",
    "                for i, (name1, name2, score) in enumerate(org_dupes, 1):\n",
    "                    if shown >= 10:\n",
    "                        break\n",
    "                    \n",
    "                    # Check if both orgs still exist\n",
    "                    o1 = session.run(\n",
    "                        \"MATCH (o:Organization {name: $name}) RETURN o.name as name\",\n",
    "                        name=name1\n",
    "                    ).single()\n",
    "                    o2 = session.run(\n",
    "                        \"MATCH (o:Organization {name: $name}) RETURN o.name as name\",\n",
    "                        name=name2\n",
    "                    ).single()\n",
    "                    \n",
    "                    if not o1 or not o2:\n",
    "                        continue\n",
    "                    \n",
    "                    shown += 1\n",
    "                    print(f\"  [{shown}] Similarity: {score:.3f}\")\n",
    "                    print(f\"      Org A: {name1}\")\n",
    "                    print(f\"      Org B: {name2}\")\n",
    "                    print()\n",
    "            \n",
    "            if len(org_dupes) > 10:\n",
    "                print(f\"  ... and {len(org_dupes) - 10} more duplicate pair(s)\")\n",
    "        \n",
    "        # Summary\n",
    "        total_potential_merges = len(person_dupes) + len(org_dupes)\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"SUMMARY: {total_potential_merges} potential merge(s) identified\")\n",
    "        print(f\"  â€¢ {len(person_dupes)} person merge(s)\")\n",
    "        print(f\"  â€¢ {len(org_dupes)} organization merge(s)\")\n",
    "        \n",
    "        if total_potential_merges > 0:\n",
    "            estimated_reduction = len(person_dupes) + len(org_dupes)\n",
    "            print(f\"\\nEstimated node reduction: {estimated_reduction} nodes\")\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "    def resolve_all(self, person_threshold: float = 0.95, org_threshold: float = 0.90):\n",
    "        \"\"\"\n",
    "        Run complete entity resolution process.\n",
    "        \n",
    "        Args:\n",
    "            person_threshold: Similarity threshold for persons (0-1)\n",
    "            org_threshold: Similarity threshold for organizations (0-1)\n",
    "            \n",
    "        Process:\n",
    "        1. Capture BEFORE statistics\n",
    "        2. Find and merge duplicate persons\n",
    "        3. Find and merge duplicate organizations\n",
    "        4. Capture AFTER statistics\n",
    "        5. Display comparison\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"{'ENTITY RESOLUTION STARTING':^70}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # BEFORE stats\n",
    "        print(\"\\n[1/4] Capturing BEFORE statistics...\")\n",
    "        self.stats_before = GraphStats.get_stats(self.driver)\n",
    "        GraphStats.print_stats(self.stats_before, \"BEFORE ENTITY RESOLUTION\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Resolve Persons\n",
    "        print(f\"\\n[2/4] Resolving Persons (threshold={person_threshold})...\")\n",
    "        person_dupes = self.find_duplicate_persons(person_threshold)\n",
    "        print(f\"  Found {len(person_dupes)} potential person duplicates\")\n",
    "        \n",
    "        person_merge_count = 0\n",
    "        person_skip_count = 0\n",
    "        for keep, merge, score in person_dupes:\n",
    "            try:\n",
    "                if not keep or not merge or keep == merge:\n",
    "                    person_skip_count += 1\n",
    "                    continue\n",
    "                if str(keep) == 'None' or str(merge) == 'None':\n",
    "                    person_skip_count += 1\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    Merging {merge} -> {keep} (similarity: {score:.3f})\")\n",
    "                self.merge_persons(keep, merge)\n",
    "                person_merge_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Failed to merge {merge} -> {keep}: {e}\")\n",
    "                person_skip_count += 1\n",
    "        \n",
    "        print(f\"  âœ“ Successfully merged {person_merge_count} person node(s)\")\n",
    "        if person_skip_count > 0:\n",
    "            print(f\"  âš  Skipped {person_skip_count} invalid merge(s)\")\n",
    "        \n",
    "        # Resolve Organizations\n",
    "        print(f\"\\n[3/4] Resolving Organizations (threshold={org_threshold})...\")\n",
    "        org_dupes = self.find_duplicate_organizations(org_threshold)\n",
    "        print(f\"  Found {len(org_dupes)} potential organization duplicates\")\n",
    "        \n",
    "        org_merge_count = 0\n",
    "        org_skip_count = 0\n",
    "        for keep, merge, score in org_dupes:\n",
    "            try:\n",
    "                if not keep or not merge or keep == merge:\n",
    "                    org_skip_count += 1\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    Merging '{merge}' -> '{keep}' (similarity: {score:.3f})\")\n",
    "                self.merge_organizations(keep, merge)\n",
    "                org_merge_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Failed to merge '{merge}' -> '{keep}': {e}\")\n",
    "                org_skip_count += 1\n",
    "        \n",
    "        print(f\"  âœ“ Successfully merged {org_merge_count} organization node(s)\")\n",
    "        if org_skip_count > 0:\n",
    "            print(f\"  âš  Skipped {org_skip_count} invalid merge(s)\")\n",
    "        \n",
    "        # AFTER stats\n",
    "        print(f\"\\n[4/4] Capturing AFTER statistics...\")\n",
    "        self.stats_after = GraphStats.get_stats(self.driver)\n",
    "        GraphStats.print_stats(self.stats_after, \"AFTER ENTITY RESOLUTION\")\n",
    "        \n",
    "        # Comparison\n",
    "        GraphStats.print_comparison(self.stats_before, self.stats_after)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nâ±ï¸  Entity Resolution completed in {elapsed:.2f} seconds\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# MAIN PIPELINE\n",
    "# =====================================================================\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    JSONL_PATH = \"/qwen_output_v1.jsonl\"\n",
    "    NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "    NEO4J_USER = \"neo4j\"\n",
    "    NEO4J_PW = \"your_password\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"KNOWLEDGE GRAPH IMPORT & ENTITY RESOLUTION PIPELINE (FIXED)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # STEP 1: Import all data (creates duplicates)\n",
    "    print(\"\\n[STEP 1/3] Importing JSONL data...\")\n",
    "    import_jsonl_to_neo4j(\n",
    "        jsonl_path=JSONL_PATH,\n",
    "        uri=NEO4J_URI,\n",
    "        user=NEO4J_USER,\n",
    "        password=NEO4J_PW,\n",
    "        log_every=50\n",
    "    )\n",
    "    \n",
    "    # STEP 2: Preview duplicates (optional - shows what will be merged)\n",
    "    print(\"\\n[STEP 2/3] Previewing potential duplicates...\")\n",
    "    resolver = EntityResolver(NEO4J_URI, NEO4J_USER, NEO4J_PW)\n",
    "    try:\n",
    "        resolver.preview_duplicates(\n",
    "            person_threshold=0.95,  # Conservative threshold\n",
    "            org_threshold=0.90\n",
    "        )\n",
    "        \n",
    "        # STEP 3: Entity resolution (merges duplicates) automatically\n",
    "        print(\"\\n[STEP 3/3] Running entity resolution...\")\n",
    "        resolver.resolve_all(\n",
    "            person_threshold=0.95,  # High threshold = only merge very similar\n",
    "            org_threshold=0.90\n",
    "        )\n",
    "        \n",
    "    finally:\n",
    "        resolver.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAS_200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
